{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Bộ dữ liệu TehranHouse.csv chứa các thông tin về bất động sản ở Tehran, gồm các thuộc tính như:\n",
        "\n",
        "* Area (diện tích): Loại dữ liệu chuỗi, mô tả khu vực hoặc địa chỉ của căn nhà.\n",
        "* Room (số phòng): Số nguyên, số phòng trong căn nhà.\n",
        "* Parking: Dữ liệu dạng boolean (True/False), thể hiện nhà có chỗ đỗ xe hay không.\n",
        "* Warehouse: Dữ liệu dạng boolean, chỉ định nhà có nhà kho hay không.\n",
        "* Elevator: Dữ liệu dạng boolean, chỉ định nhà có thang máy hay không.\n",
        "* Address: Loại dữ liệu chuỗi, địa chỉ chi tiết của căn nhà.\n",
        "* Price: Giá của căn nhà, kiểu dữ liệu số thực (float64).\n",
        "* Price(USD): Giá của căn nhà quy đổi ra USD, cũng là kiểu dữ liệu số thực.\n",
        "\n",
        "\n",
        "Mục tiêu của bài toán là xây dựng một mô hình học máy để dự đoán giá nhà dựa trên các thuộc tính có sẵn trong bộ dữ liệu.\n",
        "\n",
        "\n",
        "\n",
        "Mô tả bài toán và mục tiêu\n",
        "Bài toán này là bài toán hồi quy sử dụng mô hình rừng ngẫu nhiên (Random Forest) trong thư viện tensorflow_decision_forests. Mục tiêu là huấn luyện mô hình với dữ liệu huấn luyện và đánh giá mô hình với dữ liệu kiểm thử để dự đoán chính xác giá nhà (biến mục tiêu)."
      ],
      "metadata": {
        "id": "Dg3vmWXqWADE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cài đặt thư viện TensorFlow Decision Forests**"
      ],
      "metadata": {
        "id": "Vb_h-ouwElHo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow_decision_forests"
      ],
      "metadata": {
        "id": "TJRdM8IyJ58_",
        "outputId": "0e57d16e-8e73-48aa-c110-5ec5d4232d03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow_decision_forests\n",
            "  Downloading tensorflow_decision_forests-1.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (2.2.2)\n",
            "Collecting tensorflow==2.18.0 (from tensorflow_decision_forests)\n",
            "  Downloading tensorflow-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (1.16.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (1.4.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (0.44.0)\n",
            "Collecting wurlitzer (from tensorflow_decision_forests)\n",
            "  Downloading wurlitzer-3.1.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: tf-keras~=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (2.17.0)\n",
            "Collecting ydf (from tensorflow_decision_forests)\n",
            "  Downloading ydf-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.18.0->tensorflow_decision_forests) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.18.0->tensorflow_decision_forests) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.18.0->tensorflow_decision_forests) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.18.0->tensorflow_decision_forests) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.18.0->tensorflow_decision_forests) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.18.0->tensorflow_decision_forests) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.18.0->tensorflow_decision_forests) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.18.0->tensorflow_decision_forests) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.18.0->tensorflow_decision_forests) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.18.0->tensorflow_decision_forests) (75.1.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.18.0->tensorflow_decision_forests) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.18.0->tensorflow_decision_forests) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.18.0->tensorflow_decision_forests) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.18.0->tensorflow_decision_forests) (1.67.1)\n",
            "Collecting tensorboard<2.19,>=2.18 (from tensorflow==2.18.0->tensorflow_decision_forests)\n",
            "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting keras>=3.5.0 (from tensorflow==2.18.0->tensorflow_decision_forests)\n",
            "  Downloading keras-3.6.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.18.0->tensorflow_decision_forests) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.18.0->tensorflow_decision_forests) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.18.0->tensorflow_decision_forests) (0.37.1)\n",
            "INFO: pip is looking at multiple versions of tf-keras to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tf-keras~=2.17 (from tensorflow_decision_forests)\n",
            "  Downloading tf_keras-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->tensorflow_decision_forests) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->tensorflow_decision_forests) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->tensorflow_decision_forests) (2024.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow==2.18.0->tensorflow_decision_forests) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow==2.18.0->tensorflow_decision_forests) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow==2.18.0->tensorflow_decision_forests) (0.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.18.0->tensorflow_decision_forests) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.18.0->tensorflow_decision_forests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.18.0->tensorflow_decision_forests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.18.0->tensorflow_decision_forests) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow==2.18.0->tensorflow_decision_forests) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow==2.18.0->tensorflow_decision_forests) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow==2.18.0->tensorflow_decision_forests) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow==2.18.0->tensorflow_decision_forests) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.5.0->tensorflow==2.18.0->tensorflow_decision_forests) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.5.0->tensorflow==2.18.0->tensorflow_decision_forests) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow==2.18.0->tensorflow_decision_forests) (0.1.2)\n",
            "Downloading tensorflow_decision_forests-1.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (615.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m615.3/615.3 MB\u001b[0m \u001b[31m812.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tf_keras-2.18.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m69.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wurlitzer-3.1.1-py3-none-any.whl (8.6 kB)\n",
            "Downloading ydf-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.3/9.3 MB\u001b[0m \u001b[31m94.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-3.6.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m85.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ydf, wurlitzer, tensorboard, keras, tensorflow, tf-keras, tensorflow_decision_forests\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.17.0\n",
            "    Uninstalling tensorboard-2.17.0:\n",
            "      Successfully uninstalled tensorboard-2.17.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.4.1\n",
            "    Uninstalling keras-3.4.1:\n",
            "      Successfully uninstalled keras-3.4.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.17.0\n",
            "    Uninstalling tensorflow-2.17.0:\n",
            "      Successfully uninstalled tensorflow-2.17.0\n",
            "  Attempting uninstall: tf-keras\n",
            "    Found existing installation: tf_keras 2.17.0\n",
            "    Uninstalling tf_keras-2.17.0:\n",
            "      Successfully uninstalled tf_keras-2.17.0\n",
            "Successfully installed keras-3.6.0 tensorboard-2.18.0 tensorflow-2.18.0 tensorflow_decision_forests-1.11.0 tf-keras-2.18.0 wurlitzer-3.1.1 ydf-0.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install wurlitzer"
      ],
      "metadata": {
        "id": "2B4rOzHUKZJ0",
        "outputId": "498c5fa0-f101-4960-b208-c7b3ae6edf49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wurlitzer in /usr/local/lib/python3.10/dist-packages (3.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Đây là các lệnh cài đặt tensorflow_decision_forests để sử dụng mô hình rừng quyết định trong TensorFlow và wurlitzer để hỗ trợ hiển thị đầu ra."
      ],
      "metadata": {
        "id": "ltDMJYZ_WNww"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import thư viện**"
      ],
      "metadata": {
        "id": "Mcw4xqIqKnhR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# Keep using Keras 2\n",
        "os.environ['TF_USE_LEGACY_KERAS'] = '1'\n",
        "\n",
        "import tensorflow_decision_forests as tfdf\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tf_keras\n",
        "import math"
      ],
      "metadata": {
        "id": "62ldorhMKrFN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "outputId": "42952196-fd46-4366-fe25-41bcf2d8d3b9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<p style=\"margin:0px;\">🌲 Try <a href=\"https://ydf.readthedocs.io/en/latest/\" target=\"_blank\">YDF</a>, the successor of\n",
              "    <a href=\"https://www.tensorflow.org/decision_forests\" target=\"_blank\">TensorFlow\n",
              "        Decision Forests</a> using the same algorithms but with more features and faster\n",
              "    training!\n",
              "</p>\n",
              "<div style=\"display: flex; flex-wrap: wrap; margin:5px;max-width: 880px;\">\n",
              "    <div style=\"flex: 1; border-radius: 10px; background-color: F0F0F0; padding: 5px;\">\n",
              "        <p\n",
              "            style=\"font-weight: bold; margin:0px;text-align: center;border-bottom: 1px solid #C0C0C0;margin-bottom: 4px;\">\n",
              "            Old code</p>\n",
              "        <pre style=\"overflow-wrap: anywhere; overflow: auto; margin:0px;font-size: 9pt;\">\n",
              "import tensorflow_decision_forests as tfdf\n",
              "\n",
              "tf_ds = tfdf.keras.pd_dataframe_to_tf_dataset(ds, label=\"l\")\n",
              "model = tfdf.keras.RandomForestModel(label=\"l\")\n",
              "model.fit(tf_ds)\n",
              "</pre>\n",
              "    </div>\n",
              "    <div style=\"width: 5px;\"></div>\n",
              "    <div style=\"flex: 1; border-radius: 10px; background-color: F0F0F0; padding: 5px;\">\n",
              "        <p\n",
              "            style=\"font-weight: bold; margin:0px;text-align: center;border-bottom: 1px solid #C0C0C0;margin-bottom: 4px;\">\n",
              "            New code</p>\n",
              "        <pre style=\"overflow-wrap: anywhere; overflow: auto; margin:0px;font-size: 9pt;\">\n",
              "import ydf\n",
              "\n",
              "model = ydf.RandomForestLearner(label=\"l\").train(ds)\n",
              "</pre>\n",
              "    </div>\n",
              "</div>\n",
              "<p style=\"margin:0px;font-size: 9pt;\">(Learn more in the <a\n",
              "        href=\"https://ydf.readthedocs.io/en/latest/tutorial/migrating_to_ydf/\" target=\"_blank\">migration\n",
              "        guide</a>)</p>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cấu hình môi trường và import các thư viện cần thiết như TensorFlow, Pandas, NumPy."
      ],
      "metadata": {
        "id": "wNsF_yvPWRLf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Kiểm tra phiên bản Decision Forest**"
      ],
      "metadata": {
        "id": "uK3ImUKzLmFn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the dataset\n",
        "!wget -q https://storage.googleapis.com/download.tensorflow.org/data/palmer_penguins/penguins.csv -O /tmp/penguins.csv\n",
        "\n",
        "# Load a dataset into a Pandas Dataframe.\n",
        "dataset_df = pd.read_csv(\"/content/TehranHouse.csv\")\n",
        "\n",
        "# Display the first 3 examples.\n",
        "dataset_df.head(3)"
      ],
      "metadata": {
        "id": "-My9QL0BMIg3",
        "outputId": "94eb02a1-87b4-42bc-abd6-0534aac2c800",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Area  Room  Parking  Warehouse  Elevator  Address         Price  Price(USD)\n",
              "0   63     1     True       True      True  Shahran  1.850000e+09    61666.67\n",
              "1   60     1     True       True      True  Shahran  1.850000e+09    61666.67\n",
              "2   79     2     True       True      True   Pardis  5.500000e+08    18333.33"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9f97e233-a56e-40ea-b142-2a3cbc073319\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Area</th>\n",
              "      <th>Room</th>\n",
              "      <th>Parking</th>\n",
              "      <th>Warehouse</th>\n",
              "      <th>Elevator</th>\n",
              "      <th>Address</th>\n",
              "      <th>Price</th>\n",
              "      <th>Price(USD)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>63</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>Shahran</td>\n",
              "      <td>1.850000e+09</td>\n",
              "      <td>61666.67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>60</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>Shahran</td>\n",
              "      <td>1.850000e+09</td>\n",
              "      <td>61666.67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>79</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>Pardis</td>\n",
              "      <td>5.500000e+08</td>\n",
              "      <td>18333.33</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9f97e233-a56e-40ea-b142-2a3cbc073319')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9f97e233-a56e-40ea-b142-2a3cbc073319 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9f97e233-a56e-40ea-b142-2a3cbc073319');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3e0913ee-3f1b-4afa-aebf-612beba6e33c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3e0913ee-3f1b-4afa-aebf-612beba6e33c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3e0913ee-3f1b-4afa-aebf-612beba6e33c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dataset_df",
              "summary": "{\n  \"name\": \"dataset_df\",\n  \"rows\": 3479,\n  \"fields\": [\n    {\n      \"column\": \"Area\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 243,\n        \"samples\": [\n          \"90\",\n          \"87\",\n          \"162\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Room\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 5,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          1,\n          2,\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Parking\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          false,\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Warehouse\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          false,\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Elevator\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          false,\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Address\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 192,\n        \"samples\": [\n          \"Marzdaran\",\n          \"Vahidieh\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Price\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8099934524.3331995,\n        \"min\": 3600000.0,\n        \"max\": 92400000000.0,\n        \"num_unique_values\": 934,\n        \"samples\": [\n          3310000000.0,\n          1300000000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Price(USD)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 269997.817408084,\n        \"min\": 120.0,\n        \"max\": 3080000.0,\n        \"num_unique_values\": 932,\n        \"samples\": [\n          13233.33,\n          43333.33\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bộ dữ liệu được tải về và đọc vào DataFrame của Pandas. Đoạn code có thể tải nhầm dữ liệu không liên quan (penguins), cần chú ý đường dẫn chính xác."
      ],
      "metadata": {
        "id": "76l_28DVWXfp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode the categorical labels as integers.\n",
        "#\n",
        "# Details:\n",
        "# This stage is necessary if your classification label is represented as a\n",
        "# string since Keras expects integer classification labels.\n",
        "# When using `pd_dataframe_to_tf_dataset` (see below), this step can be skipped.\n",
        "\n",
        "# Name of the label column.\n",
        "label = \"Price\"\n",
        "\n",
        "classes = dataset_df[label].unique().tolist()\n",
        "print(f\"Label classes: {classes}\")\n",
        "\n",
        "dataset_df[label] = dataset_df[label].map(classes.index)"
      ],
      "metadata": {
        "id": "0sjld62QMfpN",
        "outputId": "e8552327-92b3-4571-c322-7bc050a325b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label classes: [1850000000.0, 550000000.0, 902500000.0, 7000000000.0, 2050000000.0, 600000000.0, 2150000000.0, 493000000.0, 2370000000.0, 2450000000.0, 2100000000.0, 1690000000.0, 11000000000.0, 5000000000.0, 570000000.0, 6700000000.0, 1450000000.0, 6400000000.0, 1390000000.0, 2500000000.0, 1880000000.0, 2277000000.0, 7150000000.0, 14945000000.0, 1771000000.0, 4059000000.0, 630000000.0, 3200000000.0, 1500000000.0, 2200000000.0, 7872000000.0, 2350000000.0, 3750000000.0, 5250000000.0, 4830000000.0, 3400000000.0, 3850000000.0, 1200000000.0, 2650000000.0, 4750000000.0, 2980000000.0, 2035000000.0, 2460000000.0, 540000000.0, 10000000000.0, 635000000.0, 2030000000.0, 3000000000.0, 7200000000.0, 1750000000.0, 3300000000.0, 2800000000.0, 3500000000.0, 3100000000.0, 1920000000.0, 850000000.0, 1650000000.0, 1700000000.0, 560000000.0, 5500000000.0, 10200000000.0, 1760000000.0, 3730000000.0, 620000000.0, 580000000.0, 3050000000.0, 2000000000.0, 2600000000.0, 5990000000.0, 2300000000.0, 1300000000.0, 2270000000.0, 4000000000.0, 650000000.0, 16900000000.0, 248000000.0, 510000000.0, 6000000000.0, 780000000.0, 410000000.0, 430000000.0, 800000000.0, 545000000.0, 1280000000.0, 11200000000.0, 750000000.0, 3280000000.0, 4800000000.0, 7300000000.0, 3950000000.0, 370000000.0, 1725000000.0, 1419000000.0, 3600000000.0, 1050000000.0, 340000000.0, 3600000.0, 165000000.0, 2860000000.0, 3810000000.0, 1790000000.0, 1530000000.0, 1000000000.0, 1800000000.0, 20000000000.0, 950000000.0, 3700000000.0, 605000000.0, 9900000000.0, 10480000000.0, 7632000000.0, 12300000000.0, 26950000000.0, 24300000000.0, 4700000000.0, 9180000000.0, 1579500000.0, 12000000000.0, 3780000000.0, 8100000000.0, 9100000000.0, 1550000000.0, 1640000000.0, 2750000000.0, 15400000000.0, 350000000.0, 4115000000.0, 8000000000.0, 7500000000.0, 2400000000.0, 1100000000.0, 24000000000.0, 3820000000.0, 5800000000.0, 15750000000.0, 3968000000.0, 1909000000.0, 37800000000.0, 5700000000.0, 10490000000.0, 7400000000.0, 6200000000.0, 21500000000.0, 1886000000.0, 2323000000.0, 6800000000.0, 20700000000.0, 6250000000.0, 1863000000.0, 13000000000.0, 12500000000.0, 17000000000.0, 8500000000.0, 3350000000.0, 27000000000.0, 12600000000.0, 1702000000.0, 700000000.0, 15600000000.0, 15350000000.0, 2810000000.0, 395000000.0, 15100000000.0, 715000000.0, 4260000000.0, 2120000000.0, 590000000.0, 1930000000.0, 2730000000.0, 3150000000.0, 4600000000.0, 4500000000.0, 5100000000.0, 625000000.0, 1620000000.0, 17050000000.0, 17600000000.0, 2250000000.0, 25300000000.0, 11700000000.0, 4400000000.0, 22750000000.0, 4300000000.0, 3380000000.0, 6500000000.0, 3220000000.0, 6240000000.0, 3650000000.0, 15500000000.0, 4200000000.0, 3900000000.0, 6600000000.0, 810000000.0, 3680000000.0, 12670000000.0, 9200000000.0, 5200000000.0, 3550000000.0, 1950000000.0, 2280000000.0, 7800000000.0, 2900000000.0, 1900000000.0, 10500000000.0, 17500000000.0, 2842000000.0, 3120000000.0, 8860000000.0, 4550000000.0, 16580000000.0, 3250000000.0, 52500000000.0, 3450000000.0, 2490000000.0, 8400000000.0, 2020000000.0, 3800000000.0, 5300000000.0, 33500000000.0, 40000000000.0, 19500000000.0, 14800000000.0, 14700000000.0, 22000000000.0, 16450000000.0, 25000000000.0, 45000000000.0, 17672000000.0, 12400000000.0, 27720000000.0, 18700000000.0, 2570000000.0, 16200000000.0, 13800000000.0, 18500000000.0, 5600000000.0, 1890000000.0, 5400000000.0, 1417500000.0, 1585000000.0, 3270000000.0, 2380000000.0, 12800000000.0, 11800000000.0, 875000000.0, 2630000000.0, 9270000000.0, 7700000000.0, 12850000000.0, 4018000000.0, 10688000000.0, 2130000000.0, 4100000000.0, 4520000000.0, 980000000.0, 22500000000.0, 14000000000.0, 38500000000.0, 680000000.0, 5180000000.0, 2580000000.0, 3370000000.0, 6480000000.0, 8900000000.0, 85000000000.0, 55000000000.0, 880000000.0, 9360000000.0, 9840000000.0, 14484000000.0, 55500000000.0, 1270000000.0, 1990000000.0, 1817000000.0, 585000000.0, 990000000.0, 4190000000.0, 4099000000.0, 36500000000.0, 1225000000.0, 3840000000.0, 8600000000.0, 6264000000.0, 2260000000.0, 1633000000.0, 2244000000.0, 1570000000.0, 295000000.0, 3130000000.0, 1960000000.0, 3230000000.0, 690000000.0, 3480000000.0, 35000000000.0, 760000000.0, 2891700000.0, 455000000.0, 1600000000.0, 610000000.0, 1870000000.0, 740000000.0, 18145000000.0, 2093000000.0, 36660000000.0, 30000000000.0, 23100000000.0, 7140000000.0, 2047000000.0, 3990000000.0, 7448000000.0, 8200000000.0, 15000000000.0, 2510000000.0, 3570000000.0, 11475000000.0, 1260000000.0, 42000000000.0, 9500000000.0, 32000000000.0, 19000000000.0, 29700000000.0, 3310000000.0, 7830000000.0, 8700000000.0, 19300000000.0, 4650000000.0, 53950000000.0, 8960000000.0, 9515000000.0, 2700000000.0, 5661000000.0, 4240000000.0, 12150000000.0, 11100000000.0, 9000000000.0, 1181100000.0, 1150800000.0, 1012000000.0, 1365000000.0, 10800000000.0, 7600000000.0, 2080000000.0, 22050000000.0, 4140000000.0, 9300000000.0, 795000000.0, 7040000000.0, 9400000000.0, 2024000000.0, 24700000000.0, 2180000000.0, 17200000000.0, 26500000000.0, 670000000.0, 955000000.0, 500000000.0, 7541000000.0, 10700000000.0, 26000000000.0, 1275000000.0, 490000000.0, 4350000000.0, 1978000000.0, 1955000000.0, 2139000000.0, 1630000000.0, 9800000000.0, 3580000000.0, 2850000000.0, 8350000000.0, 2970000000.0, 460000000.0, 1090000000.0, 1035000000.0, 1245000000.0, 1510000000.0, 16160000000.0, 450000000.0, 2950000000.0, 4590000000.0, 7485000000.0, 11250000000.0, 60000000.0, 11500000000.0, 900000000.0, 6100000000.0, 730000000.0, 23000000000.0, 7950000000.0, 960000000.0, 9450000000.0, 6050000000.0, 7980000000.0, 6300000000.0, 7900000000.0, 3795000000.0, 1109700000.0, 1250000000.0, 1608000000.0, 315000000.0, 2210000000.0, 3170000000.0, 5550000000.0, 5950000000.0, 1574000000.0, 1712000000.0, 4230000000.0, 32500000000.0, 1150000000.0, 2575000000.0, 440000000.0, 81600000000.0, 11600000000.0, 1830000000.0, 514000000.0, 75000000000.0, 3620000000.0, 7474000000.0, 1720000000.0, 8450000000.0, 3160000000.0, 726000000.0, 2870000000.0, 3940000000.0, 15225000000.0, 7550000000.0, 8800000000.0, 940000000.0, 1110000000.0, 1590000000.0, 5544000000.0, 389000000.0, 1484000000.0, 25900000000.0, 1242000000.0, 380000000.0, 995000000.0, 1380000000.0, 565000000.0, 2760000000.0, 2330000000.0, 870000000.0, 1980000000.0, 4170000000.0, 1780000000.0, 1860000000.0, 470000000.0, 2555000000.0, 1970000000.0, 3762000000.0, 13625000000.0, 18715000000.0, 4050000000.0, 4660000000.0, 6625000000.0, 400000000.0, 2240000000.0, 2920000000.0, 520000000.0, 535000000.0, 8990000000.0, 1580000000.0, 4480000000.0, 1875000000.0, 5750000000.0, 6900000000.0, 47450000000.0, 10230000000.0, 5080000000.0, 11375000000.0, 35200000000.0, 16300000000.0, 425000000.0, 7425000000.0, 3670000000.0, 725000000.0, 7100000000.0, 770000000.0, 1507000000.0, 4450000000.0, 1030000000.0, 6890000000.0, 2185000000.0, 1206000000.0, 9750000000.0, 3420000000.0, 8750000000.0, 13500000000.0, 4180000000.0, 8320000000.0, 3410000000.0, 1679000000.0, 2090000000.0, 4130000000.0, 375000000.0, 1420000000.0, 4250000000.0, 18000000000.0, 2930000000.0, 2220000000.0, 36000000000.0, 2170000000.0, 2830000000.0, 2430000000.0, 6560000000.0, 32640000000.0, 2530000000.0, 2113000000.0, 2108000000.0, 12325000000.0, 2385000000.0, 8890000000.0, 3920000000.0, 1400000000.0, 896000000.0, 19845000000.0, 9150000000.0, 6958000000.0, 5616000000.0, 1230000000.0, 890000000.0, 4370000000.0, 9645000000.0, 4850000000.0, 9850000000.0, 1272000000.0, 48000000000.0, 14500000000.0, 790000000.0, 10750000000.0, 2999000000.0, 56000000000.0, 860000000.0, 6670000000.0, 31668000000.0, 11400000000.0, 4150000000.0, 19858000000.0, 705500000.0, 1554000000.0, 5588000000.0, 539000000.0, 3190000000.0, 4900000000.0, 33490000000.0, 13120000000.0, 18400000000.0, 43197000000.0, 1315000000.0, 80500000000.0, 21000000000.0, 17250000000.0, 210000000.0, 16000000000.0, 30800000000.0, 3859000000.0, 37000000000.0, 862500000.0, 5655000000.0, 8642000000.0, 42840000000.0, 4512000000.0, 3360000000.0, 4730000000.0, 6490000000.0, 9238000000.0, 7350000000.0, 14850000000.0, 9350000000.0, 60000000000.0, 38000000000.0, 6660000000.0, 11456000000.0, 46000000000.0, 5650000000.0, 34000000000.0, 34800000000.0, 355000000.0, 2924000000.0, 12650000000.0, 6420000000.0, 2688000000.0, 480000000.0, 3690000000.0, 4225000000.0, 15700000000.0, 910000000.0, 735000000.0, 665000000.0, 14950000000.0, 8300000000.0, 4840000000.0, 1020000000.0, 975000000.0, 1610000000.0, 485000000.0, 250000000.0, 7850000000.0, 2910000000.0, 20292000000.0, 360000000.0, 21700000000.0, 555000000.0, 45500000000.0, 5050000000.0, 920000000.0, 1048000000.0, 46900000000.0, 6760000000.0, 720000000.0, 22100000000.0, 19800000000.0, 3024000000.0, 525000000.0, 3345000000.0, 2550000000.0, 1680000000.0, 14300000000.0, 830000000.0, 365000000.0, 2694000000.0, 57500000000.0, 5580000000.0, 13600000000.0, 21560000000.0, 16800000000.0, 1340000000.0, 1615000000.0, 2480000000.0, 9898000000.0, 3880000000.0, 80000000000.0, 4680000000.0, 3520000000.0, 92400000000.0, 2230000000.0, 6150000000.0, 9860000000.0, 2560000000.0, 50000000000.0, 2990000000.0, 15950000000.0, 1098000000.0, 882000000.0, 12580000000.0, 5405000000.0, 1638000000.0, 9600000000.0, 11060000000.0, 13175000000.0, 8055000000.0, 6120000000.0, 91000000000.0, 16400000000.0, 5555000000.0, 63000000000.0, 345000000.0, 982000000.0, 3060000000.0, 930000000.0, 945000000.0, 3870000000.0, 2190000000.0, 5150000000.0, 2960000000.0, 13300000000.0, 33600000000.0, 4128000000.0, 710000000.0, 1820000000.0, 17280000000.0, 11150000000.0, 1360000000.0, 530000000.0, 640000000.0, 19900000000.0, 6640000000.0, 25500000000.0, 13200000000.0, 13700000000.0, 1318000000.0, 4780000000.0, 13400000000.0, 1320000000.0, 14200000000.0, 2590000000.0, 1730000000.0, 1135200000.0, 1040000000.0, 479000000.0, 496000000.0, 6565000000.0, 475000000.0, 1350000000.0, 765000000.0, 5850000000.0, 3584000000.0, 4870000000.0, 3395000000.0, 12350000000.0, 4725000000.0, 1265000000.0, 3330000000.0, 1062000000.0, 820000000.0, 773000000.0, 9720000000.0, 31000000000.0, 3110000000.0, 10368000000.0, 72000000000.0, 2010000000.0, 1070000000.0, 110000000.0, 1290000000.0, 1220000000.0, 2160000000.0, 1187000000.0, 1210000000.0, 1215000000.0, 1068000000.0, 1440000000.0, 1415000000.0, 1310000000.0, 999000000.0, 417000000.0, 6144000000.0, 6160000000.0, 1540000000.0, 28500000000.0, 1794000000.0, 815000000.0, 4640000000.0, 660000000.0, 385000000.0, 29000000000.0, 2680000000.0, 12825000000.0, 1330000000.0, 901000000.0, 838000000.0, 1078000000.0, 1349550000.0, 840000000.0, 1460000000.0, 755000000.0, 745000000.0, 1140000000.0, 1130000000.0, 1150100000.0, 965000000.0, 15800000000.0, 1430000000.0, 2435000000.0, 9114000000.0, 7990000000.0, 74400000000.0, 33840000000.0, 297000000.0, 1670000000.0, 1375000000.0, 1180000000.0, 420000000.0, 868000000.0, 1370000000.0, 1155000000.0, 1160000000.0, 1312000000.0, 714000000.0, 505000000.0, 20250000000.0, 695000000.0, 3760000000.0, 1874500000.0, 1957300000.0, 2283900000.0, 2071150000.0, 835000000.0, 18750000000.0, 1490000000.0, 2360000000.0, 4826000000.0, 4440000000.0, 6465000000.0, 320000000.0, 411000000.0, 310000000.0, 10600000000.0, 305000000.0, 255000000.0, 275000000.0, 245000000.0, 4125000000.0, 4530000000.0, 7676000000.0, 1410000000.0, 405000000.0, 1520000000.0, 28800000000.0, 1013000000.0, 658000000.0, 2420000000.0, 435000000.0, 10150000000.0, 1204000000.0, 2153000000.0, 2390000000.0, 280000000.0, 1442000000.0, 260000000.0, 330000000.0, 390000000.0, 8250000000.0, 9780000000.0, 2720000000.0, 2310000000.0, 1985000000.0, 1134000000.0, 30360000000.0, 5985000000.0, 6840000000.0, 353000000.0, 70000000000.0, 5280000000.0, 754000000.0, 102000000.0, 33330000000.0, 675000000.0, 4085000000.0, 397000000.0, 2115000000.0, 938400000.0, 10640000000.0, 3490000000.0, 1840000000.0, 55000000.0, 300000000.0, 1755000000.0, 1185000000.0, 1113000000.0, 3240000000.0, 2440000000.0, 1120000000.0, 1060000000.0, 46200000000.0, 858500000.0, 806000000.0, 2620000000.0, 3980000000.0, 20900000000.0, 2640000000.0, 5252000000.0, 8475000000.0, 1145000000.0, 218000000.0, 240000000.0, 235000000.0, 6230000000.0, 1745000000.0, 2820000000.0, 17655000000.0, 9970000000.0, 10300000000.0, 1740000000.0, 2975000000.0, 488000000.0, 7770000000.0, 12100000000.0, 6175000000.0, 515000000.0, 79500000000.0, 649000000.0, 18200000000.0, 2340000000.0, 668000000.0, 2880000000.0, 12750000000.0, 2715000000.0, 7630000000.0, 75600000000.0, 1885000000.0, 4070000000.0, 11385000000.0, 4080000000.0, 4950000000.0, 465000000.0, 1792000000.0, 2410000000.0, 421000000.0, 1699010000.0, 1536000000.0, 1170000000.0, 15200000000.0, 34560000000.0, 3590000000.0, 398000000.0, 28000000000.0, 645000000.0, 682000000.0, 8610000000.0, 2376000000.0, 8660000000.0, 11760000000.0, 5060000000.0, 1125000000.0, 18150000000.0, 588000000.0, 797500000.0, 290000000.0, 7250000000.0, 6550000000.0, 13950000000.0, 3440000000.0, 708000000.0, 5175000000.0, 15563000000.0, 8150000000.0, 1650000088.0, 22500000003.0, 5830000000.0, 855000000.0, 1470000000.0, 1286500000.0, 8140000000.0, 7597000000.0, 865000000.0, 246000000.0, 313000000.0, 6850000000.0, 7080000000.0, 325000000.0, 595000000.0, 1258000000.0, 4455000000.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mã hóa cột Price để biến nó thành dạng số nguyên phù hợp cho việc huấn luyện mô hình."
      ],
      "metadata": {
        "id": "m84x09eQWZcT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chia tập dữ liệu để huấn luyện và kiểm tra"
      ],
      "metadata": {
        "id": "UNAK5U85MvTn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into a training and a testing dataset.\n",
        "\n",
        "def split_dataset(dataset, test_ratio=0.30):\n",
        "  \"\"\"Splits a panda dataframe in two.\"\"\"\n",
        "  test_indices = np.random.rand(len(dataset)) < test_ratio\n",
        "  return dataset[~test_indices], dataset[test_indices]\n",
        "\n",
        "\n",
        "train_ds_pd, test_ds_pd = split_dataset(dataset_df)\n",
        "print(\"{} examples in training, {} examples for testing.\".format(\n",
        "    len(train_ds_pd), len(test_ds_pd)))"
      ],
      "metadata": {
        "id": "4B91pqK7M13D",
        "outputId": "a3d42503-5aef-4fb2-b884-8521ca0a6340",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2439 examples in training, 1040 examples for testing.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hàm split_dataset chia dữ liệu thành 70% huấn luyện và 30% kiểm thử."
      ],
      "metadata": {
        "id": "fepQDptUWc2X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds_pd['Warehouse'] = train_ds_pd['Warehouse'].astype(int)\n",
        "train_ds_pd['Elevator'] = train_ds_pd['Elevator'].astype(int)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvRo2u59DWON",
        "outputId": "d7f08eb4-16fe-4100-ffa8-2850ce7a5612"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-e56e49e05bb0>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train_ds_pd['Warehouse'] = train_ds_pd['Warehouse'].astype(int)\n",
            "<ipython-input-18-e56e49e05bb0>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train_ds_pd['Elevator'] = train_ds_pd['Elevator'].astype(int)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "chuyển đổi khung dữ liệu gấu trúc thành bộ dữ liệu"
      ],
      "metadata": {
        "id": "BvIVlNkINyLN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chuyển đổi các cột Warehouse và Elevator sang kiểu int để đảm bảo tính nhất quán."
      ],
      "metadata": {
        "id": "wt3ltUz5WfTA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_ds_pd, label=label, max_num_classes=800)\n",
        "test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(test_ds_pd, label=label, max_num_classes=800)"
      ],
      "metadata": {
        "id": "OCn6uggZNz6C"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hàm pd_dataframe_to_tf_dataset sẽ tự động chuyển đổi các nhãn dạng chuỗi thành số nguyên nếu cần."
      ],
      "metadata": {
        "id": "Hy0XkJeKcU6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_1 = tfdf.keras.RandomForestModel(verbose=2)\n",
        "\n",
        "# Train the model.\n",
        "model_1.fit(train_ds)"
      ],
      "metadata": {
        "id": "nDoPMgz8OCGO",
        "outputId": "e778d9aa-7274-486f-8bf8-b17edcd5ca2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use 2 thread(s) for training\n",
            "Use /tmp/tmpawsdo21k as temporary training directory\n",
            "Reading training dataset...\n",
            "Training tensor examples:\n",
            "Features: {'Area': <tf.Tensor 'data:0' shape=(None,) dtype=string>, 'Room': <tf.Tensor 'data_1:0' shape=(None,) dtype=int64>, 'Parking': <tf.Tensor 'data_2:0' shape=(None,) dtype=int64>, 'Warehouse': <tf.Tensor 'data_3:0' shape=(None,) dtype=int64>, 'Elevator': <tf.Tensor 'data_4:0' shape=(None,) dtype=int64>, 'Address': <tf.Tensor 'data_5:0' shape=(None,) dtype=string>, 'Price(USD)': <tf.Tensor 'data_6:0' shape=(None,) dtype=float64>}\n",
            "Label: Tensor(\"data_7:0\", shape=(None,), dtype=int64)\n",
            "Weights: None\n",
            "Normalized tensor features:\n",
            " {'Area': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'data:0' shape=(None,) dtype=string>), 'Room': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast:0' shape=(None,) dtype=float32>), 'Parking': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_1:0' shape=(None,) dtype=float32>), 'Warehouse': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_2:0' shape=(None,) dtype=float32>), 'Elevator': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_3:0' shape=(None,) dtype=float32>), 'Address': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'data_5:0' shape=(None,) dtype=string>), 'Price(USD)': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_4:0' shape=(None,) dtype=float32>)}\n",
            "Training dataset read in 0:00:01.551583. Found 2439 examples.\n",
            "Training model...\n",
            "Standard output detected as not visible to the user e.g. running in a notebook. Creating a training log redirection. If training gets stuck, try calling tfdf.keras.set_training_logs_redirection(False).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1731544098.234226     874 kernel.cc:782] Start Yggdrasil model training\n",
            "I0000 00:00:1731544098.234298     874 kernel.cc:783] Collect training examples\n",
            "I0000 00:00:1731544098.234315     874 kernel.cc:795] Dataspec guide:\n",
            "column_guides {\n",
            "  column_name_pattern: \"^__LABEL$\"\n",
            "  type: CATEGORICAL\n",
            "  categorial {\n",
            "    min_vocab_frequency: 0\n",
            "    max_vocab_count: -1\n",
            "  }\n",
            "}\n",
            "default_column_guide {\n",
            "  categorial {\n",
            "    max_vocab_count: 2000\n",
            "  }\n",
            "  discretized_numerical {\n",
            "    maximum_num_bins: 255\n",
            "  }\n",
            "}\n",
            "ignore_columns_without_guides: false\n",
            "detect_numerical_as_discretized_numerical: false\n",
            "\n",
            "I0000 00:00:1731544098.234981     874 kernel.cc:401] Number of batches: 3\n",
            "I0000 00:00:1731544098.235024     874 kernel.cc:402] Number of examples: 2439\n",
            "I0000 00:00:1731544098.235817     874 data_spec_inference.cc:354] 96 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Address (82 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "I0000 00:00:1731544098.235964     874 data_spec_inference.cc:354] 105 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Area (115 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "I0000 00:00:1731544098.236426     874 kernel.cc:802] Training dataset:\n",
            "Number of records: 2439\n",
            "Number of columns: 8\n",
            "\n",
            "Number of columns by type:\n",
            "\tNUMERICAL: 5 (62.5%)\n",
            "\tCATEGORICAL: 3 (37.5%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "NUMERICAL: 5 (62.5%)\n",
            "\t2: \"Elevator\" NUMERICAL mean:0.787208 min:0 max:1 sd:0.409282\n",
            "\t3: \"Parking\" NUMERICAL mean:0.849118 min:0 max:1 sd:0.357933\n",
            "\t4: \"Price(USD)\" NUMERICAL mean:177347 min:120 max:3.08e+06 sd:269702\n",
            "\t5: \"Room\" NUMERICAL mean:2.08241 min:0 max:5 sd:0.756124\n",
            "\t6: \"Warehouse\" NUMERICAL mean:0.915129 min:0 max:1 sd:0.278689\n",
            "\n",
            "CATEGORICAL: 3 (37.5%)\n",
            "\t0: \"Address\" CATEGORICAL num-nas:15 (0.615006%) has-dict vocab-size:83 num-oods:186 (7.67327%) most-frequent:\"<OOD>\" 186 (7.67327%)\n",
            "\t1: \"Area\" CATEGORICAL has-dict vocab-size:116 num-oods:175 (7.17507%) most-frequent:\"<OOD>\" 175 (7.17507%)\n",
            "\t7: \"__LABEL\" CATEGORICAL integerized vocab-size:934 no-ood-item\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "I0000 00:00:1731544098.236489     874 kernel.cc:818] Configure learner\n",
            "I0000 00:00:1731544098.236778     874 kernel.cc:831] Training config:\n",
            "learner: \"RANDOM_FOREST\"\n",
            "features: \"^Address$\"\n",
            "features: \"^Area$\"\n",
            "features: \"^Elevator$\"\n",
            "features: \"^Parking$\"\n",
            "features: \"^Price\\\\(USD\\\\)$\"\n",
            "features: \"^Room$\"\n",
            "features: \"^Warehouse$\"\n",
            "label: \"^__LABEL$\"\n",
            "task: CLASSIFICATION\n",
            "random_seed: 123456\n",
            "metadata {\n",
            "  framework: \"TF Keras\"\n",
            "}\n",
            "pure_serving_model: false\n",
            "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
            "  num_trees: 300\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    keep_non_leaf_label_distribution: true\n",
            "    num_candidate_attributes: 0\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "    uplift {\n",
            "      min_examples_in_treatment: 5\n",
            "      split_score: KULLBACK_LEIBLER\n",
            "    }\n",
            "  }\n",
            "  winner_take_all_inference: true\n",
            "  compute_oob_performances: true\n",
            "  compute_oob_variable_importances: false\n",
            "  num_oob_variable_importances_permutations: 1\n",
            "  bootstrap_training_dataset: true\n",
            "  bootstrap_size_ratio: 1\n",
            "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
            "  sampling_with_replacement: true\n",
            "}\n",
            "\n",
            "I0000 00:00:1731544098.240537     874 kernel.cc:834] Deployment config:\n",
            "cache_path: \"/tmp/tmpawsdo21k/working_cache\"\n",
            "num_threads: 2\n",
            "try_resume_training: true\n",
            "\n",
            "I0000 00:00:1731544098.246340    4241 kernel.cc:895] Train model\n",
            "I0000 00:00:1731544098.246727    4241 random_forest.cc:427] Training random forest on 2439 example(s) and 7 feature(s).\n",
            "I0000 00:00:1731544107.531188    4245 random_forest.cc:811] Training of tree  1/300 (tree index:1) done accuracy:0.246652 logloss:27.1534\n",
            "I0000 00:00:1731544117.938673    4245 random_forest.cc:811] Training of tree  3/300 (tree index:2) done accuracy:0.286424 logloss:24.1032\n",
            "I0000 00:00:1731544131.870802    4245 random_forest.cc:811] Training of tree  5/300 (tree index:4) done accuracy:0.299816 logloss:22.362\n",
            "I0000 00:00:1731544148.307466    4245 random_forest.cc:811] Training of tree  7/300 (tree index:6) done accuracy:0.313036 logloss:20.9646\n",
            "I0000 00:00:1731544159.674140    4245 random_forest.cc:811] Training of tree  9/300 (tree index:8) done accuracy:0.331529 logloss:19.5512\n",
            "I0000 00:00:1731544173.399248    4245 random_forest.cc:811] Training of tree  11/300 (tree index:10) done accuracy:0.341303 logloss:18.4161\n",
            "I0000 00:00:1731544186.935064    4245 random_forest.cc:811] Training of tree  13/300 (tree index:12) done accuracy:0.347433 logloss:17.6478\n",
            "I0000 00:00:1731544197.106630    4245 random_forest.cc:811] Training of tree  15/300 (tree index:14) done accuracy:0.352483 logloss:16.8642\n",
            "I0000 00:00:1731544211.146924    4244 random_forest.cc:811] Training of tree  17/300 (tree index:17) done accuracy:0.370386 logloss:15.9789\n",
            "I0000 00:00:1731544222.972463    4245 random_forest.cc:811] Training of tree  19/300 (tree index:19) done accuracy:0.378844 logloss:15.456\n",
            "I0000 00:00:1731544233.436079    4244 random_forest.cc:811] Training of tree  21/300 (tree index:21) done accuracy:0.380894 logloss:15.0182\n",
            "I0000 00:00:1731544248.722690    4244 random_forest.cc:811] Training of tree  23/300 (tree index:22) done accuracy:0.394834 logloss:14.4959\n",
            "I0000 00:00:1731544260.051874    4245 random_forest.cc:811] Training of tree  25/300 (tree index:25) done accuracy:0.405904 logloss:14.1365\n",
            "I0000 00:00:1731544270.686808    4245 random_forest.cc:811] Training of tree  27/300 (tree index:26) done accuracy:0.414924 logloss:13.5987\n",
            "I0000 00:00:1731544283.074826    4245 random_forest.cc:811] Training of tree  29/300 (tree index:28) done accuracy:0.418204 logloss:13.2363\n",
            "I0000 00:00:1731544294.033167    4245 random_forest.cc:811] Training of tree  31/300 (tree index:30) done accuracy:0.421894 logloss:12.9409\n",
            "I0000 00:00:1731544311.314373    4245 random_forest.cc:811] Training of tree  34/300 (tree index:34) done accuracy:0.436244 logloss:12.4586\n",
            "I0000 00:00:1731544321.331537    4245 random_forest.cc:811] Training of tree  36/300 (tree index:35) done accuracy:0.441574 logloss:12.2958\n",
            "I0000 00:00:1731544333.418528    4244 random_forest.cc:811] Training of tree  39/300 (tree index:38) done accuracy:0.448134 logloss:11.9137\n",
            "I0000 00:00:1731544352.213409    4245 random_forest.cc:811] Training of tree  42/300 (tree index:41) done accuracy:0.457565 logloss:11.4609\n",
            "I0000 00:00:1731544363.267985    4244 random_forest.cc:811] Training of tree  44/300 (tree index:44) done accuracy:0.461255 logloss:11.3898\n",
            "I0000 00:00:1731544373.928427    4245 random_forest.cc:811] Training of tree  46/300 (tree index:46) done accuracy:0.465765 logloss:11.2128\n",
            "I0000 00:00:1731544384.017293    4245 random_forest.cc:811] Training of tree  48/300 (tree index:47) done accuracy:0.462895 logloss:11.1637\n",
            "I0000 00:00:1731544396.980838    4245 random_forest.cc:811] Training of tree  50/300 (tree index:49) done accuracy:0.465355 logloss:11.0727\n",
            "I0000 00:00:1731544408.353332    4245 random_forest.cc:811] Training of tree  52/300 (tree index:51) done accuracy:0.469045 logloss:10.9901\n",
            "I0000 00:00:1731544418.509266    4244 random_forest.cc:811] Training of tree  54/300 (tree index:54) done accuracy:0.473555 logloss:10.7664\n",
            "I0000 00:00:1731544433.270228    4245 random_forest.cc:811] Training of tree  56/300 (tree index:56) done accuracy:0.476835 logloss:10.6906\n",
            "I0000 00:00:1731544447.084489    4244 random_forest.cc:811] Training of tree  59/300 (tree index:58) done accuracy:0.482985 logloss:10.4596\n",
            "I0000 00:00:1731544474.543234    4245 random_forest.cc:811] Training of tree  62/300 (tree index:61) done accuracy:0.487905 logloss:10.3527\n",
            "I0000 00:00:1731544494.756985    4245 random_forest.cc:811] Training of tree  64/300 (tree index:63) done accuracy:0.488315 logloss:10.3307\n",
            "I0000 00:00:1731544505.630654    4245 random_forest.cc:811] Training of tree  66/300 (tree index:65) done accuracy:0.489955 logloss:10.2795\n",
            "I0000 00:00:1731544516.574468    4245 random_forest.cc:811] Training of tree  68/300 (tree index:67) done accuracy:0.489135 logloss:10.1747\n",
            "I0000 00:00:1731544531.036213    4244 random_forest.cc:811] Training of tree  71/300 (tree index:70) done accuracy:0.492005 logloss:10.0476\n",
            "I0000 00:00:1731544543.050727    4244 random_forest.cc:811] Training of tree  73/300 (tree index:72) done accuracy:0.493645 logloss:9.96465\n",
            "I0000 00:00:1731544556.353535    4244 random_forest.cc:811] Training of tree  75/300 (tree index:74) done accuracy:0.494055 logloss:9.92335\n",
            "I0000 00:00:1731544571.596135    4245 random_forest.cc:811] Training of tree  77/300 (tree index:77) done accuracy:0.498975 logloss:9.80929\n",
            "I0000 00:00:1731544586.355575    4244 random_forest.cc:811] Training of tree  80/300 (tree index:79) done accuracy:0.502665 logloss:9.71606\n",
            "I0000 00:00:1731544605.103154    4245 random_forest.cc:811] Training of tree  83/300 (tree index:82) done accuracy:0.505125 logloss:9.63356\n",
            "I0000 00:00:1731544617.298825    4245 random_forest.cc:811] Training of tree  85/300 (tree index:84) done accuracy:0.505945 logloss:9.60977\n",
            "I0000 00:00:1731544628.435248    4245 random_forest.cc:811] Training of tree  87/300 (tree index:86) done accuracy:0.510045 logloss:9.5448\n",
            "I0000 00:00:1731544645.621006    4244 random_forest.cc:811] Training of tree  90/300 (tree index:89) done accuracy:0.510455 logloss:9.49617\n",
            "I0000 00:00:1731544663.537683    4245 random_forest.cc:811] Training of tree  93/300 (tree index:92) done accuracy:0.513325 logloss:9.41895\n",
            "I0000 00:00:1731544676.495173    4244 random_forest.cc:811] Training of tree  96/300 (tree index:95) done accuracy:0.512505 logloss:9.34001\n",
            "I0000 00:00:1731544688.270599    4244 random_forest.cc:811] Training of tree  98/300 (tree index:97) done accuracy:0.514145 logloss:9.28236\n",
            "I0000 00:00:1731544701.952441    4244 random_forest.cc:811] Training of tree  100/300 (tree index:99) done accuracy:0.514145 logloss:9.27321\n",
            "I0000 00:00:1731544717.329457    4245 random_forest.cc:811] Training of tree  103/300 (tree index:102) done accuracy:0.518655 logloss:9.20461\n",
            "I0000 00:00:1731544728.409602    4245 random_forest.cc:811] Training of tree  105/300 (tree index:104) done accuracy:0.518245 logloss:9.16647\n",
            "I0000 00:00:1731544742.613223    4245 random_forest.cc:811] Training of tree  107/300 (tree index:106) done accuracy:0.517835 logloss:9.16622\n",
            "I0000 00:00:1731544752.945085    4244 random_forest.cc:811] Training of tree  108/300 (tree index:107) done accuracy:0.518245 logloss:9.16826\n",
            "I0000 00:00:1731544763.229248    4244 random_forest.cc:811] Training of tree  110/300 (tree index:109) done accuracy:0.518245 logloss:9.12973\n",
            "I0000 00:00:1731544773.837475    4244 random_forest.cc:811] Training of tree  112/300 (tree index:111) done accuracy:0.519065 logloss:9.1144\n",
            "I0000 00:00:1731544786.075390    4245 random_forest.cc:811] Training of tree  114/300 (tree index:114) done accuracy:0.525625 logloss:9.01481\n",
            "I0000 00:00:1731544796.212482    4244 random_forest.cc:811] Training of tree  116/300 (tree index:116) done accuracy:0.525625 logloss:8.98907\n",
            "I0000 00:00:1731544807.848084    4245 random_forest.cc:811] Training of tree  118/300 (tree index:118) done accuracy:0.526035 logloss:8.97666\n",
            "I0000 00:00:1731544818.051636    4245 random_forest.cc:811] Training of tree  120/300 (tree index:119) done accuracy:0.528905 logloss:8.9508\n",
            "I0000 00:00:1731544828.151475    4245 random_forest.cc:811] Training of tree  122/300 (tree index:121) done accuracy:0.530955 logloss:8.89728\n",
            "I0000 00:00:1731544839.972928    4245 random_forest.cc:811] Training of tree  124/300 (tree index:123) done accuracy:0.530545 logloss:8.89838\n",
            "I0000 00:00:1731544856.338903    4244 random_forest.cc:811] Training of tree  127/300 (tree index:127) done accuracy:0.533005 logloss:8.88372\n",
            "I0000 00:00:1731544869.469000    4245 random_forest.cc:811] Training of tree  130/300 (tree index:129) done accuracy:0.536695 logloss:8.88219\n",
            "I0000 00:00:1731544882.662516    4245 random_forest.cc:811] Training of tree  132/300 (tree index:131) done accuracy:0.536285 logloss:8.84536\n",
            "I0000 00:00:1731544899.270842    4245 random_forest.cc:811] Training of tree  135/300 (tree index:134) done accuracy:0.532595 logloss:8.81676\n",
            "I0000 00:00:1731544910.316980    4245 random_forest.cc:811] Training of tree  137/300 (tree index:136) done accuracy:0.530135 logloss:8.8159\n",
            "I0000 00:00:1731544921.930975    4245 random_forest.cc:811] Training of tree  139/300 (tree index:138) done accuracy:0.530955 logloss:8.80399\n",
            "I0000 00:00:1731544934.303599    4245 random_forest.cc:811] Training of tree  141/300 (tree index:140) done accuracy:0.533005 logloss:8.76673\n",
            "I0000 00:00:1731544944.396561    4245 random_forest.cc:811] Training of tree  143/300 (tree index:142) done accuracy:0.533825 logloss:8.7507\n",
            "I0000 00:00:1731544954.908465    4245 random_forest.cc:811] Training of tree  145/300 (tree index:144) done accuracy:0.534235 logloss:8.69674\n",
            "I0000 00:00:1731544969.977304    4245 random_forest.cc:811] Training of tree  147/300 (tree index:146) done accuracy:0.533415 logloss:8.69868\n",
            "I0000 00:00:1731544983.818742    4244 random_forest.cc:811] Training of tree  150/300 (tree index:149) done accuracy:0.535055 logloss:8.68568\n",
            "I0000 00:00:1731544996.831324    4244 random_forest.cc:811] Training of tree  152/300 (tree index:151) done accuracy:0.534645 logloss:8.68895\n",
            "I0000 00:00:1731545009.966895    4244 random_forest.cc:811] Training of tree  154/300 (tree index:153) done accuracy:0.534235 logloss:8.67708\n",
            "I0000 00:00:1731545024.834523    4244 random_forest.cc:811] Training of tree  157/300 (tree index:155) done accuracy:0.534235 logloss:8.67469\n",
            "I0000 00:00:1731545035.028527    4245 random_forest.cc:811] Training of tree  158/300 (tree index:157) done accuracy:0.534645 logloss:8.67647\n",
            "I0000 00:00:1731545047.961547    4245 random_forest.cc:811] Training of tree  160/300 (tree index:159) done accuracy:0.535875 logloss:8.66496\n",
            "I0000 00:00:1731545059.111501    4245 random_forest.cc:811] Training of tree  162/300 (tree index:161) done accuracy:0.535465 logloss:8.66647\n",
            "I0000 00:00:1731545074.872839    4244 random_forest.cc:811] Training of tree  165/300 (tree index:164) done accuracy:0.537515 logloss:8.63745\n",
            "I0000 00:00:1731545089.301195    4245 random_forest.cc:811] Training of tree  168/300 (tree index:167) done accuracy:0.536695 logloss:8.59559\n",
            "I0000 00:00:1731545100.496532    4245 random_forest.cc:811] Training of tree  170/300 (tree index:169) done accuracy:0.536695 logloss:8.5948\n",
            "I0000 00:00:1731545112.025310    4244 random_forest.cc:811] Training of tree  172/300 (tree index:170) done accuracy:0.535875 logloss:8.56888\n",
            "I0000 00:00:1731545122.575876    4245 random_forest.cc:811] Training of tree  173/300 (tree index:172) done accuracy:0.536285 logloss:8.56974\n",
            "I0000 00:00:1731545136.457844    4245 random_forest.cc:811] Training of tree  176/300 (tree index:174) done accuracy:0.536285 logloss:8.55546\n",
            "I0000 00:00:1731545147.513930    4245 random_forest.cc:811] Training of tree  178/300 (tree index:177) done accuracy:0.537515 logloss:8.52815\n",
            "I0000 00:00:1731545158.146221    4244 random_forest.cc:811] Training of tree  179/300 (tree index:178) done accuracy:0.537105 logloss:8.52768\n",
            "I0000 00:00:1731545169.131603    4244 random_forest.cc:811] Training of tree  181/300 (tree index:180) done accuracy:0.538335 logloss:8.52763\n",
            "I0000 00:00:1731545181.322514    4244 random_forest.cc:811] Training of tree  183/300 (tree index:182) done accuracy:0.537925 logloss:8.50423\n",
            "I0000 00:00:1731545196.183535    4244 random_forest.cc:811] Training of tree  185/300 (tree index:184) done accuracy:0.537105 logloss:8.49337\n",
            "I0000 00:00:1731545206.184440    4245 random_forest.cc:811] Training of tree  187/300 (tree index:187) done accuracy:0.538335 logloss:8.48149\n",
            "I0000 00:00:1731545216.639748    4245 random_forest.cc:811] Training of tree  189/300 (tree index:188) done accuracy:0.539565 logloss:8.40054\n",
            "I0000 00:00:1731545230.123056    4245 random_forest.cc:811] Training of tree  191/300 (tree index:190) done accuracy:0.537105 logloss:8.37762\n",
            "I0000 00:00:1731545242.376238    4245 random_forest.cc:811] Training of tree  194/300 (tree index:192) done accuracy:0.538335 logloss:8.36108\n",
            "I0000 00:00:1731545253.809654    4245 random_forest.cc:811] Training of tree  196/300 (tree index:195) done accuracy:0.538745 logloss:8.36343\n",
            "I0000 00:00:1731545272.914879    4244 random_forest.cc:811] Training of tree  199/300 (tree index:198) done accuracy:0.541205 logloss:8.33676\n",
            "I0000 00:00:1731545284.281069    4245 random_forest.cc:811] Training of tree  202/300 (tree index:201) done accuracy:0.542845 logloss:8.32078\n",
            "I0000 00:00:1731545301.216467    4244 random_forest.cc:811] Training of tree  205/300 (tree index:204) done accuracy:0.544895 logloss:8.29207\n",
            "I0000 00:00:1731545317.559028    4245 random_forest.cc:811] Training of tree  208/300 (tree index:207) done accuracy:0.545715 logloss:8.27777\n",
            "I0000 00:00:1731545330.798144    4245 random_forest.cc:811] Training of tree  210/300 (tree index:209) done accuracy:0.544485 logloss:8.27907\n",
            "I0000 00:00:1731545345.716045    4244 random_forest.cc:811] Training of tree  213/300 (tree index:212) done accuracy:0.547765 logloss:8.25147\n",
            "I0000 00:00:1731545356.097558    4244 random_forest.cc:811] Training of tree  215/300 (tree index:214) done accuracy:0.547765 logloss:8.23814\n",
            "I0000 00:00:1731545366.773924    4245 random_forest.cc:811] Training of tree  217/300 (tree index:215) done accuracy:0.549815 logloss:8.23705\n",
            "I0000 00:00:1731545377.540024    4245 random_forest.cc:811] Training of tree  219/300 (tree index:218) done accuracy:0.550636 logloss:8.19307\n",
            "I0000 00:00:1731545397.084796    4244 random_forest.cc:811] Training of tree  222/300 (tree index:221) done accuracy:0.551046 logloss:8.17822\n",
            "I0000 00:00:1731545409.827451    4244 random_forest.cc:811] Training of tree  224/300 (tree index:223) done accuracy:0.550636 logloss:8.16725\n",
            "I0000 00:00:1731545420.394154    4244 random_forest.cc:811] Training of tree  226/300 (tree index:225) done accuracy:0.550636 logloss:8.15235\n",
            "I0000 00:00:1731545435.265524    4244 random_forest.cc:811] Training of tree  228/300 (tree index:227) done accuracy:0.550225 logloss:8.15421\n",
            "I0000 00:00:1731545447.079988    4244 random_forest.cc:811] Training of tree  230/300 (tree index:229) done accuracy:0.549815 logloss:8.14194\n",
            "I0000 00:00:1731545458.752942    4244 random_forest.cc:811] Training of tree  232/300 (tree index:231) done accuracy:0.548175 logloss:8.14277\n",
            "I0000 00:00:1731545471.528302    4245 random_forest.cc:811] Training of tree  235/300 (tree index:234) done accuracy:0.548175 logloss:8.13985\n",
            "I0000 00:00:1731545488.547094    4244 random_forest.cc:811] Training of tree  238/300 (tree index:237) done accuracy:0.548995 logloss:8.12376\n",
            "I0000 00:00:1731545504.339026    4245 random_forest.cc:811] Training of tree  241/300 (tree index:240) done accuracy:0.549406 logloss:8.10882\n",
            "I0000 00:00:1731545515.102875    4244 random_forest.cc:811] Training of tree  244/300 (tree index:243) done accuracy:0.550636 logloss:8.09279\n",
            "I0000 00:00:1731545526.428393    4244 random_forest.cc:811] Training of tree  245/300 (tree index:245) done accuracy:0.550225 logloss:8.093\n",
            "I0000 00:00:1731545539.865792    4244 random_forest.cc:811] Training of tree  247/300 (tree index:246) done accuracy:0.550636 logloss:8.09543\n",
            "I0000 00:00:1731545551.128721    4244 random_forest.cc:811] Training of tree  249/300 (tree index:248) done accuracy:0.550636 logloss:8.09525\n",
            "I0000 00:00:1731545562.373152    4245 random_forest.cc:811] Training of tree  251/300 (tree index:251) done accuracy:0.551455 logloss:8.08173\n",
            "I0000 00:00:1731545575.990083    4245 random_forest.cc:811] Training of tree  253/300 (tree index:252) done accuracy:0.551866 logloss:8.08324\n",
            "I0000 00:00:1731545590.155692    4245 random_forest.cc:811] Training of tree  255/300 (tree index:254) done accuracy:0.551866 logloss:8.05728\n",
            "I0000 00:00:1731545602.464968    4244 random_forest.cc:811] Training of tree  257/300 (tree index:257) done accuracy:0.550636 logloss:8.05679\n",
            "I0000 00:00:1731545612.968744    4245 random_forest.cc:811] Training of tree  259/300 (tree index:259) done accuracy:0.548585 logloss:8.05595\n",
            "I0000 00:00:1731545628.627630    4245 random_forest.cc:811] Training of tree  261/300 (tree index:260) done accuracy:0.548585 logloss:8.05854\n",
            "I0000 00:00:1731545640.431454    4244 random_forest.cc:811] Training of tree  263/300 (tree index:263) done accuracy:0.548995 logloss:8.04645\n",
            "I0000 00:00:1731545650.786794    4244 random_forest.cc:811] Training of tree  265/300 (tree index:264) done accuracy:0.548995 logloss:8.04524\n",
            "I0000 00:00:1731545662.461527    4244 random_forest.cc:811] Training of tree  267/300 (tree index:266) done accuracy:0.548585 logloss:8.03302\n",
            "I0000 00:00:1731545673.365833    4244 random_forest.cc:811] Training of tree  269/300 (tree index:268) done accuracy:0.546945 logloss:8.01968\n",
            "I0000 00:00:1731545684.135266    4245 random_forest.cc:811] Training of tree  271/300 (tree index:271) done accuracy:0.546945 logloss:8.01885\n",
            "I0000 00:00:1731545698.191785    4244 random_forest.cc:811] Training of tree  274/300 (tree index:273) done accuracy:0.547355 logloss:8.02031\n",
            "I0000 00:00:1731545709.551691    4244 random_forest.cc:811] Training of tree  276/300 (tree index:275) done accuracy:0.547765 logloss:8.0208\n",
            "I0000 00:00:1731545724.952125    4245 random_forest.cc:811] Training of tree  279/300 (tree index:278) done accuracy:0.547355 logloss:7.99389\n",
            "I0000 00:00:1731545735.292182    4245 random_forest.cc:811] Training of tree  281/300 (tree index:280) done accuracy:0.546125 logloss:7.99425\n",
            "I0000 00:00:1731545745.677062    4245 random_forest.cc:811] Training of tree  283/300 (tree index:282) done accuracy:0.545715 logloss:7.99477\n",
            "I0000 00:00:1731545756.935956    4245 random_forest.cc:811] Training of tree  285/300 (tree index:284) done accuracy:0.545305 logloss:7.99485\n",
            "I0000 00:00:1731545768.284022    4245 random_forest.cc:811] Training of tree  287/300 (tree index:286) done accuracy:0.544895 logloss:7.99411\n",
            "I0000 00:00:1731545780.398432    4245 random_forest.cc:811] Training of tree  289/300 (tree index:288) done accuracy:0.544485 logloss:7.9938\n",
            "I0000 00:00:1731545796.924966    4244 random_forest.cc:811] Training of tree  292/300 (tree index:291) done accuracy:0.545305 logloss:7.99424\n",
            "I0000 00:00:1731545807.780132    4244 random_forest.cc:811] Training of tree  294/300 (tree index:293) done accuracy:0.545715 logloss:7.96875\n",
            "I0000 00:00:1731545826.745000    4245 random_forest.cc:811] Training of tree  297/300 (tree index:296) done accuracy:0.546125 logloss:7.95653\n",
            "I0000 00:00:1731545838.505987    4245 random_forest.cc:811] Training of tree  299/300 (tree index:298) done accuracy:0.546125 logloss:7.94149\n",
            "I0000 00:00:1731545839.595315    4244 random_forest.cc:811] Training of tree  300/300 (tree index:299) done accuracy:0.546125 logloss:7.94191\n",
            "I0000 00:00:1731545839.595534    4241 random_forest.cc:891] Final OOB metrics: accuracy:0.546125 logloss:7.94191\n",
            "I0000 00:00:1731545839.679929    4241 kernel.cc:926] Export model in log directory: /tmp/tmpawsdo21k with prefix f449d75a8b924290\n",
            "I0000 00:00:1731545858.585299    4241 kernel.cc:944] Save model in resources\n",
            "I0000 00:00:1731545859.174251     874 abstract_model.cc:914] Model self evaluation:\n",
            "Number of predictions (without weights): 2439\n",
            "Number of predictions (with weights): 2439\n",
            "Task: CLASSIFICATION\n",
            "Label: __LABEL\n",
            "\n",
            "Accuracy: 0.546125  CI95[W][0.529304 0.562865]\n",
            "LogLoss: : 7.94191\n",
            "ErrorRate: : 0.453875\n",
            "\n",
            "Default Accuracy: : 0.0118901\n",
            "Default LogLoss: : 6.10701\n",
            "Default ErrorRate: : 0.98811\n",
            "\n",
            "Confusion Table:\n",
            "truth\\prediction\n",
            "      1   2  3   4  5  6   7  8  9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99  100  101  102  103  104  105  106  107  108  109  110  111  112  113  114  115  116  117  118  119  120  121  122  123  124  125  126  127  128  129  130  131  132  133  134  135  136  137  138  139  140  141  142  143  144  145  146  147  148  149  150  151  152  153  154  155  156  157  158  159  160  161  162  163  164  165  166  167  168  169  170  171  172  173  174  175  176  177  178  179  180  181  182  183  184  185  186  187  188  189  190  191  192  193  194  195  196  197  198  199  200  201  202  203  204  205  206  207  208  209  210  211  212  213  214  215  216  217  218  219  220  221  222  223  224  225  226  227  228  229  230  231  232  233  234  235  236  237  238  239  240  241  242  243  244  245  246  247  248  249  250  251  252  253  254  255  256  257  258  259  260  261  262  263  264  265  266  267  268  269  270  271  272  273  274  275  276  277  278  279  280  281  282  283  284  285  286  287  288  289  290  291  292  293  294  295  296  297  298  299  300  301  302  303  304  305  306  307  308  309  310  311  312  313  314  315  316  317  318  319  320  321  322  323  324  325  326  327  328  329  330  331  332  333  334  335  336  337  338  339  340  341  342  343  344  345  346  347  348  349  350  351  352  353  354  355  356  357  358  359  360  361  362  363  364  365  366  367  368  369  370  371  372  373  374  375  376  377  378  379  380  381  382  383  384  385  386  387  388  389  390  391  392  393  394  395  396  397  398  399  400  401  402  403  404  405  406  407  408  409  410  411  412  413  414  415  416  417  418  419  420  421  422  423  424  425  426  427  428  429  430  431  432  433  434  435  436  437  438  439  440  441  442  443  444  445  446  447  448  449  450  451  452  453  454  455  456  457  458  459  460  461  462  463  464  465  466  467  468  469  470  471  472  473  474  475  476  477  478  479  480  481  482  483  484  485  486  487  488  489  490  491  492  493  494  495  496  497  498  499  500  501  502  503  504  505  506  507  508  509  510  511  512  513  514  515  516  517  518  519  520  521  522  523  524  525  526  527  528  529  530  531  532  533  534  535  536  537  538  539  540  541  542  543  544  545  546  547  548  549  550  551  552  553  554  555  556  557  558  559  560  561  562  563  564  565  566  567  568  569  570  571  572  573  574  575  576  577  578  579  580  581  582  583  584  585  586  587  588  589  590  591  592  593  594  595  596  597  598  599  600  601  602  603  604  605  606  607  608  609  610  611  612  613  614  615  616  617  618  619  620  621  622  623  624  625  626  627  628  629  630  631  632  633  634  635  636  637  638  639  640  641  642  643  644  645  646  647  648  649  650  651  652  653  654  655  656  657  658  659  660  661  662  663  664  665  666  667  668  669  670  671  672  673  674  675  676  677  678  679  680  681  682  683  684  685  686  687  688  689  690  691  692  693  694  695  696  697  698  699  700  701  702  703  704  705  706  707  708  709  710  711  712  713  714  715  716  717  718  719  720  721  722  723  724  725  726  727  728  729  730  731  732  733  734  735  736  737  738  739  740  741  742  743  744  745  746  747  748  749  750  751  752  753  754  755  756  757  758  759  760  761  762  763  764  765  766  767  768  769  770  771  772  773  774  775  776  777  778  779  780  781  782  783  784  785  786  787  788  789  790  791  792  793  794  795  796  797  798  799  800  801  802  803  804  805  806  807  808  809  810  811  812  813  814  815  816  817  818  819  820  821  822  823  824  825  826  827  828  829  830  831  832  833  834  835  836  837  838  839  840  841  842  843  844  845  846  847  848  849  850  851  852  853  854  855  856  857  858  859  860  861  862  863  864  865  866  867  868  869  870  871  872  873  874  875  876  877  878  879  880  881  882  883  884  885  886  887  888  889  890  891  892  893  894  895  896  897  898  899  900  901  902  903  904  905  906  907  908  909  910  911  912  913  914  915  916  917  918  919  920  921  922  923  924  925  926  927  928  929  930  931  932  933\n",
            "  1  12   0  0   0  0  0   0  0  0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "  2   0  14  0   0  0  0   0  0  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "  3   0   0  0   0  0  0   0  0  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    \n",
            "2024-11-14 00:57:39.504638: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1206] Loading model from path /tmp/tmpawsdo21k/model/ with prefix f449d75a8b924290\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1731545867.118572     874 decision_forest.cc:761] Model loaded with 300 root(s), 206546 node(s), and 7 input feature(s).\n",
            "I0000 00:00:1731545867.122045     874 abstract_model.cc:1404] Engine \"RandomForestGeneric\" built\n",
            "2024-11-14 00:57:47.122093: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1035] Use fast generic engine\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model trained in 0:29:29.207921\n",
            "Compiling model...\n",
            "Model compiled.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf_keras.src.callbacks.History at 0x7f5f874c3310>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Khởi tạo mô hình RandomForestModel và huấn luyện với dữ liệu."
      ],
      "metadata": {
        "id": "bNBwRSDXWnk3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_ds_pd['Parking'] = train_ds_pd['Parking'].astype(int)\n",
        "train_ds_pd['Warehouse'] = train_ds_pd['Warehouse'].astype(int)\n",
        "train_ds_pd['Elevator'] = train_ds_pd['Elevator'].astype(int)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sai2kifSMY6_",
        "outputId": "30227225-5730-4200-ef0b-565a149a1815"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-54-8ad0341c8759>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train_ds_pd['Parking'] = train_ds_pd['Parking'].astype(int)\n",
            "<ipython-input-54-8ad0341c8759>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train_ds_pd['Warehouse'] = train_ds_pd['Warehouse'].astype(int)\n",
            "<ipython-input-54-8ad0341c8759>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train_ds_pd['Elevator'] = train_ds_pd['Elevator'].astype(int)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.compile(metrics=[\"Warehouse\"])"
      ],
      "metadata": {
        "id": "4PdLu8hcMHBT"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Biên dịch mô hình và đổi tên các cột dữ liệu để nhất quán."
      ],
      "metadata": {
        "id": "oFAwD28RWtz0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_ds_pd.dtypes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpfefV7eMm4j",
        "outputId": "e5f52fe9-4ad4-4d05-c914-9cb5aa8a252b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Area           object\n",
            "Room            int64\n",
            "Parking         int64\n",
            "Warehouse       int64\n",
            "Elevator        int64\n",
            "Address        object\n",
            "Price           int64\n",
            "Price(USD)    float64\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Chuẩn bị mô hình phục vụ TensorFlow**: Xuất mô hình sang định dạng SavingModel để sử dụng lại sau này"
      ],
      "metadata": {
        "id": "gfSJRr-kReBF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Đổi tên cột\n",
        "train_ds_pd.rename(columns={'Price(USD)': 'Price_USD'}, inplace=True)\n",
        "test_ds_pd.rename(columns={'Price(USD)': 'Price_USD'}, inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29qcG_7SNbYF",
        "outputId": "e1d1021e-1268-44d1-c89e-a36cc4c5ac50"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-35-c2caab7929e4>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train_ds_pd.rename(columns={'Price(USD)': 'Price_USD'}, inplace=True)\n",
            "<ipython-input-35-c2caab7929e4>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_ds_pd.rename(columns={'Price(USD)': 'Price_USD'}, inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vẽ model"
      ],
      "metadata": {
        "id": "lMopauRBSBeh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfdf.model_plotter.plot_model_in_colab(model_1, tree_idx=0, max_depth=3)"
      ],
      "metadata": {
        "id": "pDwULY-ISLzs",
        "outputId": "34e11e49-8844-42ae-fd3a-6f18cefb829f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<script src=\"https://d3js.org/d3.v6.min.js\"></script>\n",
              "<div id=\"tree_plot_bf8bbad3cc1148239fd5c8fc7c1f904f\"></div>\n",
              "<script>\n",
              "/*\n",
              " * Copyright 2021 Google LLC.\n",
              " * Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              " * you may not use this file except in compliance with the License.\n",
              " * You may obtain a copy of the License at\n",
              " *\n",
              " *     https://www.apache.org/licenses/LICENSE-2.0\n",
              " *\n",
              " * Unless required by applicable law or agreed to in writing, software\n",
              " * distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              " * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              " * See the License for the specific language governing permissions and\n",
              " * limitations under the License.\n",
              " */\n",
              "\n",
              "/**\n",
              " *  Plotting of decision trees generated by TF-DF.\n",
              " *\n",
              " *  A tree is a recursive structure of node objects.\n",
              " *  A node contains one or more of the following components:\n",
              " *\n",
              " *    - A value: Representing the output of the node. If the node is not a leaf,\n",
              " *      the value is only present for analysis i.e. it is not used for\n",
              " *      predictions.\n",
              " *\n",
              " *    - A condition : For non-leaf nodes, the condition (also known as split)\n",
              " *      defines a binary test to branch to the positive or negative child.\n",
              " *\n",
              " *    - An explanation: Generally a plot showing the relation between the label\n",
              " *      and the condition to give insights about the effect of the condition.\n",
              " *\n",
              " *    - Two children : For non-leaf nodes, the children nodes. The first\n",
              " *      children (i.e. \"node.children[0]\") is the negative children (drawn in\n",
              " *      red). The second children is the positive one (drawn in green).\n",
              " *\n",
              " */\n",
              "\n",
              "/**\n",
              " * Plots a single decision tree into a DOM element.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!tree} raw_tree Recursive tree structure.\n",
              " * @param {string} canvas_id Id of the output dom element.\n",
              " */\n",
              "function display_tree(options, raw_tree, canvas_id) {\n",
              "  console.log(options);\n",
              "\n",
              "  // Determine the node placement.\n",
              "  const tree_struct = d3.tree().nodeSize(\n",
              "      [options.node_y_offset, options.node_x_offset])(d3.hierarchy(raw_tree));\n",
              "\n",
              "  // Boundaries of the node placement.\n",
              "  let x_min = Infinity;\n",
              "  let x_max = -x_min;\n",
              "  let y_min = Infinity;\n",
              "  let y_max = -x_min;\n",
              "\n",
              "  tree_struct.each(d => {\n",
              "    if (d.x > x_max) x_max = d.x;\n",
              "    if (d.x < x_min) x_min = d.x;\n",
              "    if (d.y > y_max) y_max = d.y;\n",
              "    if (d.y < y_min) y_min = d.y;\n",
              "  });\n",
              "\n",
              "  // Size of the plot.\n",
              "  const width = y_max - y_min + options.node_x_size + options.margin * 2;\n",
              "  const height = x_max - x_min + options.node_y_size + options.margin * 2 +\n",
              "      options.node_y_offset - options.node_y_size;\n",
              "\n",
              "  const plot = d3.select(canvas_id);\n",
              "\n",
              "  // Tool tip\n",
              "  options.tooltip = plot.append('div')\n",
              "                        .attr('width', 100)\n",
              "                        .attr('height', 100)\n",
              "                        .style('padding', '4px')\n",
              "                        .style('background', '#fff')\n",
              "                        .style('box-shadow', '4px 4px 0px rgba(0,0,0,0.1)')\n",
              "                        .style('border', '1px solid black')\n",
              "                        .style('font-family', 'sans-serif')\n",
              "                        .style('font-size', options.font_size)\n",
              "                        .style('position', 'absolute')\n",
              "                        .style('z-index', '10')\n",
              "                        .attr('pointer-events', 'none')\n",
              "                        .style('display', 'none');\n",
              "\n",
              "  // Create canvas\n",
              "  const svg = plot.append('svg').attr('width', width).attr('height', height);\n",
              "  const graph =\n",
              "      svg.style('overflow', 'visible')\n",
              "          .append('g')\n",
              "          .attr('font-family', 'sans-serif')\n",
              "          .attr('font-size', options.font_size)\n",
              "          .attr(\n",
              "              'transform',\n",
              "              () => `translate(${options.margin},${\n",
              "                  - x_min + options.node_y_offset / 2 + options.margin})`);\n",
              "\n",
              "  // Plot bounding box.\n",
              "  if (options.show_plot_bounding_box) {\n",
              "    svg.append('rect')\n",
              "        .attr('width', width)\n",
              "        .attr('height', height)\n",
              "        .attr('fill', 'none')\n",
              "        .attr('stroke-width', 1.0)\n",
              "        .attr('stroke', 'black');\n",
              "  }\n",
              "\n",
              "  // Draw the edges.\n",
              "  display_edges(options, graph, tree_struct);\n",
              "\n",
              "  // Draw the nodes.\n",
              "  display_nodes(options, graph, tree_struct);\n",
              "}\n",
              "\n",
              "/**\n",
              " * Draw the nodes of the tree.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!graph} graph D3 search handle containing the graph.\n",
              " * @param {!tree_struct} tree_struct Structure of the tree (node placement,\n",
              " *     data, etc.).\n",
              " */\n",
              "function display_nodes(options, graph, tree_struct) {\n",
              "  const nodes = graph.append('g')\n",
              "                    .selectAll('g')\n",
              "                    .data(tree_struct.descendants())\n",
              "                    .join('g')\n",
              "                    .attr('transform', d => `translate(${d.y},${d.x})`);\n",
              "\n",
              "  nodes.append('rect')\n",
              "      .attr('x', 0.5)\n",
              "      .attr('y', 0.5)\n",
              "      .attr('width', options.node_x_size)\n",
              "      .attr('height', options.node_y_size)\n",
              "      .attr('stroke', 'lightgrey')\n",
              "      .attr('stroke-width', 1)\n",
              "      .attr('fill', 'white')\n",
              "      .attr('y', -options.node_y_size / 2);\n",
              "\n",
              "  // Brackets on the right of condition nodes without children.\n",
              "  non_leaf_node_without_children =\n",
              "      nodes.filter(node => node.data.condition != null && node.children == null)\n",
              "          .append('g')\n",
              "          .attr('transform', `translate(${options.node_x_size},0)`);\n",
              "\n",
              "  non_leaf_node_without_children.append('path')\n",
              "      .attr('d', 'M0,0 C 10,0 0,10 10,10')\n",
              "      .attr('fill', 'none')\n",
              "      .attr('stroke-width', 1.0)\n",
              "      .attr('stroke', '#F00');\n",
              "\n",
              "  non_leaf_node_without_children.append('path')\n",
              "      .attr('d', 'M0,0 C 10,0 0,-10 10,-10')\n",
              "      .attr('fill', 'none')\n",
              "      .attr('stroke-width', 1.0)\n",
              "      .attr('stroke', '#0F0');\n",
              "\n",
              "  const node_content = nodes.append('g').attr(\n",
              "      'transform',\n",
              "      `translate(0,${options.node_padding - options.node_y_size / 2})`);\n",
              "\n",
              "  node_content.append(node => create_node_element(options, node));\n",
              "}\n",
              "\n",
              "/**\n",
              " * Creates the D3 content for a single node.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!node} node Node to draw.\n",
              " * @return {!d3} D3 content.\n",
              " */\n",
              "function create_node_element(options, node) {\n",
              "  // Output accumulator.\n",
              "  let output = {\n",
              "    // Content to draw.\n",
              "    content: d3.create('svg:g'),\n",
              "    // Vertical offset to the next element to draw.\n",
              "    vertical_offset: 0\n",
              "  };\n",
              "\n",
              "  // Conditions.\n",
              "  if (node.data.condition != null) {\n",
              "    display_condition(options, node.data.condition, output);\n",
              "  }\n",
              "\n",
              "  // Values.\n",
              "  if (node.data.value != null) {\n",
              "    display_value(options, node.data.value, output);\n",
              "  }\n",
              "\n",
              "  // Explanations.\n",
              "  if (node.data.explanation != null) {\n",
              "    display_explanation(options, node.data.explanation, output);\n",
              "  }\n",
              "\n",
              "  return output.content.node();\n",
              "}\n",
              "\n",
              "\n",
              "/**\n",
              " * Adds a single line of text inside of a node.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {string} text Text to display.\n",
              " * @param {!output} output Output display accumulator.\n",
              " */\n",
              "function display_node_text(options, text, output) {\n",
              "  output.content.append('text')\n",
              "      .attr('x', options.node_padding)\n",
              "      .attr('y', output.vertical_offset)\n",
              "      .attr('alignment-baseline', 'hanging')\n",
              "      .text(text);\n",
              "  output.vertical_offset += 10;\n",
              "}\n",
              "\n",
              "/**\n",
              " * Adds a single line of text inside of a node with a tooltip.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {string} text Text to display.\n",
              " * @param {string} tooltip Text in the Tooltip.\n",
              " * @param {!output} output Output display accumulator.\n",
              " */\n",
              "function display_node_text_with_tooltip(options, text, tooltip, output) {\n",
              "  const item = output.content.append('text')\n",
              "                   .attr('x', options.node_padding)\n",
              "                   .attr('alignment-baseline', 'hanging')\n",
              "                   .text(text);\n",
              "\n",
              "  add_tooltip(options, item, () => tooltip);\n",
              "  output.vertical_offset += 10;\n",
              "}\n",
              "\n",
              "/**\n",
              " * Adds a tooltip to a dom element.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!dom} target Dom element to equip with a tooltip.\n",
              " * @param {!func} get_content Generates the html content of the tooltip.\n",
              " */\n",
              "function add_tooltip(options, target, get_content) {\n",
              "  function show(d) {\n",
              "    options.tooltip.style('display', 'block');\n",
              "    options.tooltip.html(get_content());\n",
              "  }\n",
              "\n",
              "  function hide(d) {\n",
              "    options.tooltip.style('display', 'none');\n",
              "  }\n",
              "\n",
              "  function move(d) {\n",
              "    options.tooltip.style('display', 'block');\n",
              "    options.tooltip.style('left', (d.pageX + 5) + 'px');\n",
              "    options.tooltip.style('top', d.pageY + 'px');\n",
              "  }\n",
              "\n",
              "  target.on('mouseover', show);\n",
              "  target.on('mouseout', hide);\n",
              "  target.on('mousemove', move);\n",
              "}\n",
              "\n",
              "/**\n",
              " * Adds a condition inside of a node.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!condition} condition Condition to display.\n",
              " * @param {!output} output Output display accumulator.\n",
              " */\n",
              "function display_condition(options, condition, output) {\n",
              "  threshold_format = d3.format('r');\n",
              "\n",
              "  if (condition.type === 'IS_MISSING') {\n",
              "    display_node_text(options, `${condition.attribute} is missing`, output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (condition.type === 'IS_TRUE') {\n",
              "    display_node_text(options, `${condition.attribute} is true`, output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (condition.type === 'NUMERICAL_IS_HIGHER_THAN') {\n",
              "    format = d3.format('r');\n",
              "    display_node_text(\n",
              "        options,\n",
              "        `${condition.attribute} >= ${threshold_format(condition.threshold)}`,\n",
              "        output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (condition.type === 'CATEGORICAL_IS_IN') {\n",
              "    display_node_text_with_tooltip(\n",
              "        options, `${condition.attribute} in [...]`,\n",
              "        `${condition.attribute} in [${condition.mask}]`, output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (condition.type === 'CATEGORICAL_SET_CONTAINS') {\n",
              "    display_node_text_with_tooltip(\n",
              "        options, `${condition.attribute} intersect [...]`,\n",
              "        `${condition.attribute} intersect [${condition.mask}]`, output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (condition.type === 'NUMERICAL_SPARSE_OBLIQUE') {\n",
              "    display_node_text_with_tooltip(\n",
              "        options, `Sparse oblique split...`,\n",
              "        `[${condition.attributes}]*[${condition.weights}]>=${\n",
              "            threshold_format(condition.threshold)}`,\n",
              "        output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  display_node_text(\n",
              "      options, `Non supported condition ${condition.type}`, output);\n",
              "}\n",
              "\n",
              "/**\n",
              " * Adds a value inside of a node.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!value} value Value to display.\n",
              " * @param {!output} output Output display accumulator.\n",
              " */\n",
              "function display_value(options, value, output) {\n",
              "  if (value.type === 'PROBABILITY') {\n",
              "    const left_margin = 0;\n",
              "    const right_margin = 50;\n",
              "    const plot_width = options.node_x_size - options.node_padding * 2 -\n",
              "        left_margin - right_margin;\n",
              "\n",
              "    let cusum = Array.from(d3.cumsum(value.distribution));\n",
              "    cusum.unshift(0);\n",
              "    const distribution_plot = output.content.append('g').attr(\n",
              "        'transform', `translate(0,${output.vertical_offset + 0.5})`);\n",
              "\n",
              "    distribution_plot.selectAll('rect')\n",
              "        .data(value.distribution)\n",
              "        .join('rect')\n",
              "        .attr('height', 10)\n",
              "        .attr(\n",
              "            'x',\n",
              "            (d, i) =>\n",
              "                (cusum[i] * plot_width + left_margin + options.node_padding))\n",
              "        .attr('width', (d, i) => d * plot_width)\n",
              "        .style('fill', (d, i) => d3.schemeSet1[i]);\n",
              "\n",
              "    const num_examples =\n",
              "        output.content.append('g')\n",
              "            .attr('transform', `translate(0,${output.vertical_offset})`)\n",
              "            .append('text')\n",
              "            .attr('x', options.node_x_size - options.node_padding)\n",
              "            .attr('alignment-baseline', 'hanging')\n",
              "            .attr('text-anchor', 'end')\n",
              "            .text(`(${value.num_examples})`);\n",
              "\n",
              "    const distribution_details = d3.create('ul');\n",
              "    distribution_details.selectAll('li')\n",
              "        .data(value.distribution)\n",
              "        .join('li')\n",
              "        .append('span')\n",
              "        .text(\n",
              "            (d, i) =>\n",
              "                'class ' + i + ': ' + d3.format('.3%')(value.distribution[i]));\n",
              "\n",
              "    add_tooltip(options, distribution_plot, () => distribution_details.html());\n",
              "    add_tooltip(options, num_examples, () => 'Number of examples');\n",
              "\n",
              "    output.vertical_offset += 10;\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (value.type === 'REGRESSION') {\n",
              "    display_node_text(\n",
              "        options,\n",
              "        'value: ' + d3.format('r')(value.value) + ` (` +\n",
              "            d3.format('.6')(value.num_examples) + `)`,\n",
              "        output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (value.type === 'UPLIFT') {\n",
              "    display_node_text(\n",
              "        options,\n",
              "        'effect: ' + d3.format('r')(value.treatment_effect) + ` (` +\n",
              "            d3.format('.6')(value.num_examples) + `)`,\n",
              "        output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  display_node_text(options, `Non supported value ${value.type}`, output);\n",
              "}\n",
              "\n",
              "/**\n",
              " * Adds an explanation inside of a node.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!explanation} explanation Explanation to display.\n",
              " * @param {!output} output Output display accumulator.\n",
              " */\n",
              "function display_explanation(options, explanation, output) {\n",
              "  // Margin before the explanation.\n",
              "  output.vertical_offset += 10;\n",
              "\n",
              "  display_node_text(\n",
              "      options, `Non supported explanation ${explanation.type}`, output);\n",
              "}\n",
              "\n",
              "\n",
              "/**\n",
              " * Draw the edges of the tree.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!graph} graph D3 search handle containing the graph.\n",
              " * @param {!tree_struct} tree_struct Structure of the tree (node placement,\n",
              " *     data, etc.).\n",
              " */\n",
              "function display_edges(options, graph, tree_struct) {\n",
              "  // Draw an edge between a parent and a child node with a bezier.\n",
              "  function draw_single_edge(d) {\n",
              "    return 'M' + (d.source.y + options.node_x_size) + ',' + d.source.x + ' C' +\n",
              "        (d.source.y + options.node_x_size + options.edge_rounding) + ',' +\n",
              "        d.source.x + ' ' + (d.target.y - options.edge_rounding) + ',' +\n",
              "        d.target.x + ' ' + d.target.y + ',' + d.target.x;\n",
              "  }\n",
              "\n",
              "  graph.append('g')\n",
              "      .attr('fill', 'none')\n",
              "      .attr('stroke-width', 1.2)\n",
              "      .selectAll('path')\n",
              "      .data(tree_struct.links())\n",
              "      .join('path')\n",
              "      .attr('d', draw_single_edge)\n",
              "      .attr(\n",
              "          'stroke', d => (d.target === d.source.children[0]) ? '#0F0' : '#F00');\n",
              "}\n",
              "\n",
              "display_tree({\"margin\": 10, \"node_x_size\": 160, \"node_y_size\": 28, \"node_x_offset\": 180, \"node_y_offset\": 33, \"font_size\": 10, \"edge_rounding\": 20, \"node_padding\": 2, \"show_plot_bounding_box\": false}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.004100041000410004, 0.007380073800738007, 0.0, 0.0036900369003690036, 0.006560065600656006, 0.0036900369003690036, 0.005330053300533005, 0.0, 0.0012300123001230013, 0.004100041000410004, 0.0024600246002460025, 0.0, 0.0024600246002460025, 0.0024600246002460025, 0.0008200082000820008, 0.0036900369003690036, 0.002870028700287003, 0.0012300123001230013, 0.0012300123001230013, 0.006560065600656006, 0.002870028700287003, 0.0004100041000410004, 0.0012300123001230013, 0.0004100041000410004, 0.0, 0.0012300123001230013, 0.0008200082000820008, 0.004510045100451004, 0.007790077900779008, 0.007790077900779008, 0.0004100041000410004, 0.0016400164001640015, 0.006150061500615006, 0.0012300123001230013, 0.0, 0.007790077900779008, 0.0012300123001230013, 0.012300123001230012, 0.0012300123001230013, 0.0, 0.0004100041000410004, 0.0008200082000820008, 0.0, 0.004100041000410004, 0.0036900369003690036, 0.0, 0.0004100041000410004, 0.007790077900779008, 0.005330053300533005, 0.004510045100451004, 0.007790077900779008, 0.006560065600656006, 0.012710127101271012, 0.005740057400574006, 0.0016400164001640015, 0.004920049200492005, 0.0036900369003690036, 0.005740057400574006, 0.002870028700287003, 0.004100041000410004, 0.0012300123001230013, 0.0004100041000410004, 0.0, 0.0008200082000820008, 0.002050020500205002, 0.0024600246002460025, 0.007790077900779008, 0.004100041000410004, 0.0, 0.008610086100861008, 0.0016400164001640015, 0.0012300123001230013, 0.004920049200492005, 0.006150061500615006, 0.0, 0.0, 0.0004100041000410004, 0.007790077900779008, 0.004510045100451004, 0.002050020500205002, 0.0008200082000820008, 0.005740057400574006, 0.0, 0.0016400164001640015, 0.0016400164001640015, 0.003280032800328003, 0.0004100041000410004, 0.0004100041000410004, 0.0036900369003690036, 0.0024600246002460025, 0.0008200082000820008, 0.0012300123001230013, 0.0008200082000820008, 0.008610086100861008, 0.006970069700697007, 0.0004100041000410004, 0.0, 0.0008200082000820008, 0.0012300123001230013, 0.0004100041000410004, 0.0004100041000410004, 0.0, 0.005740057400574006, 0.006150061500615006, 0.004100041000410004, 0.008200082000820008, 0.0004100041000410004, 0.0004100041000410004, 0.0012300123001230013, 0.0004100041000410004, 0.0, 0.0016400164001640015, 0.0, 0.0, 0.005740057400574006, 0.0004100041000410004, 0.0, 0.006150061500615006, 0.0004100041000410004, 0.0016400164001640015, 0.0004100041000410004, 0.0016400164001640015, 0.0, 0.0024600246002460025, 0.0008200082000820008, 0.0008200082000820008, 0.0004100041000410004, 0.0012300123001230013, 0.0036900369003690036, 0.005740057400574006, 0.009020090200902008, 0.0004100041000410004, 0.0012300123001230013, 0.0012300123001230013, 0.0012300123001230013, 0.0, 0.0008200082000820008, 0.0, 0.005740057400574006, 0.0, 0.002050020500205002, 0.003280032800328003, 0.0008200082000820008, 0.0, 0.0004100041000410004, 0.002870028700287003, 0.0004100041000410004, 0.0012300123001230013, 0.0004100041000410004, 0.006560065600656006, 0.0036900369003690036, 0.0016400164001640015, 0.006560065600656006, 0.0024600246002460025, 0.0024600246002460025, 0.0004100041000410004, 0.0008200082000820008, 0.0012300123001230013, 0.0004100041000410004, 0.0004100041000410004, 0.0, 0.002050020500205002, 0.0008200082000820008, 0.0008200082000820008, 0.0, 0.0008200082000820008, 0.002050020500205002, 0.0024600246002460025, 0.0008200082000820008, 0.007790077900779008, 0.0036900369003690036, 0.009020090200902008, 0.006560065600656006, 0.0004100041000410004, 0.0012300123001230013, 0.0, 0.0012300123001230013, 0.00943009430094301, 0.0008200082000820008, 0.0, 0.0008200082000820008, 0.0008200082000820008, 0.0036900369003690036, 0.0008200082000820008, 0.006970069700697007, 0.0012300123001230013, 0.0004100041000410004, 0.0012300123001230013, 0.0012300123001230013, 0.006560065600656006, 0.004510045100451004, 0.002050020500205002, 0.0016400164001640015, 0.0004100041000410004, 0.0, 0.0016400164001640015, 0.004920049200492005, 0.0008200082000820008, 0.004100041000410004, 0.0012300123001230013, 0.002050020500205002, 0.003280032800328003, 0.005330053300533005, 0.004510045100451004, 0.0012300123001230013, 0.0, 0.0012300123001230013, 0.0004100041000410004, 0.002050020500205002, 0.0, 0.005330053300533005, 0.0, 0.0008200082000820008, 0.0, 0.004920049200492005, 0.0004100041000410004, 0.002050020500205002, 0.0024600246002460025, 0.0012300123001230013, 0.0004100041000410004, 0.0004100041000410004, 0.0012300123001230013, 0.0016400164001640015, 0.002050020500205002, 0.0, 0.0012300123001230013, 0.0004100041000410004, 0.0, 0.0, 0.0, 0.0004100041000410004, 0.0, 0.0004100041000410004, 0.0008200082000820008, 0.002050020500205002, 0.003280032800328003, 0.008200082000820008, 0.002050020500205002, 0.0, 0.0016400164001640015, 0.0, 0.0016400164001640015, 0.0, 0.0008200082000820008, 0.003280032800328003, 0.0, 0.0, 0.004100041000410004, 0.0, 0.0, 0.0, 0.0004100041000410004, 0.004100041000410004, 0.0008200082000820008, 0.0, 0.0, 0.0016400164001640015, 0.0016400164001640015, 0.003280032800328003, 0.0012300123001230013, 0.0008200082000820008, 0.0004100041000410004, 0.0, 0.0016400164001640015, 0.0, 0.0, 0.0024600246002460025, 0.0008200082000820008, 0.0, 0.0, 0.0, 0.0012300123001230013, 0.0012300123001230013, 0.0004100041000410004, 0.0008200082000820008, 0.0012300123001230013, 0.0, 0.0, 0.0, 0.0, 0.0008200082000820008, 0.004100041000410004, 0.0, 0.0008200082000820008, 0.0008200082000820008, 0.0004100041000410004, 0.0012300123001230013, 0.0008200082000820008, 0.0, 0.0004100041000410004, 0.0008200082000820008, 0.0024600246002460025, 0.0008200082000820008, 0.0012300123001230013, 0.0016400164001640015, 0.0, 0.0004100041000410004, 0.004100041000410004, 0.0004100041000410004, 0.0, 0.0012300123001230013, 0.0012300123001230013, 0.0, 0.0004100041000410004, 0.0016400164001640015, 0.0008200082000820008, 0.0, 0.0004100041000410004, 0.0016400164001640015, 0.0004100041000410004, 0.004510045100451004, 0.004510045100451004, 0.0, 0.0, 0.0004100041000410004, 0.0016400164001640015, 0.0, 0.002870028700287003, 0.0, 0.0012300123001230013, 0.0, 0.0004100041000410004, 0.0, 0.0004100041000410004, 0.0, 0.0004100041000410004, 0.0, 0.0004100041000410004, 0.0, 0.007380073800738007, 0.0, 0.0, 0.0, 0.0008200082000820008, 0.004510045100451004, 0.0012300123001230013, 0.0, 0.0, 0.0004100041000410004, 0.0012300123001230013, 0.0008200082000820008, 0.002870028700287003, 0.0008200082000820008, 0.0, 0.0008200082000820008, 0.0008200082000820008, 0.0004100041000410004, 0.0004100041000410004, 0.002050020500205002, 0.0004100041000410004, 0.0, 0.0004100041000410004, 0.0004100041000410004, 0.0012300123001230013, 0.0004100041000410004, 0.003280032800328003, 0.0016400164001640015, 0.0008200082000820008, 0.0024600246002460025, 0.0, 0.0008200082000820008, 0.0016400164001640015, 0.0, 0.0, 0.0, 0.0004100041000410004, 0.0008200082000820008, 0.0004100041000410004, 0.003280032800328003, 0.0004100041000410004, 0.0, 0.0024600246002460025, 0.0004100041000410004, 0.0004100041000410004, 0.0008200082000820008, 0.0008200082000820008, 0.0004100041000410004, 0.0004100041000410004, 0.002050020500205002, 0.0012300123001230013, 0.0, 0.0008200082000820008, 0.0004100041000410004, 0.0024600246002460025, 0.008610086100861008, 0.0, 0.0004100041000410004, 0.0, 0.0, 0.0004100041000410004, 0.0, 0.0004100041000410004, 0.0004100041000410004, 0.0024600246002460025, 0.0, 0.0008200082000820008, 0.0004100041000410004, 0.005740057400574006, 0.0, 0.0004100041000410004, 0.0004100041000410004, 0.0016400164001640015, 0.002050020500205002, 0.0008200082000820008, 0.0004100041000410004, 0.0008200082000820008, 0.0, 0.0, 0.002870028700287003, 0.0012300123001230013, 0.0012300123001230013, 0.0004100041000410004, 0.0, 0.0012300123001230013, 0.0, 0.0, 0.0008200082000820008, 0.0008200082000820008, 0.0016400164001640015, 0.0, 0.0008200082000820008, 0.0, 0.0, 0.0, 0.0, 0.0016400164001640015, 0.0016400164001640015, 0.0008200082000820008, 0.0004100041000410004, 0.0, 0.0, 0.0, 0.0, 0.0008200082000820008, 0.002050020500205002, 0.0016400164001640015, 0.0012300123001230013, 0.004100041000410004, 0.0004100041000410004, 0.0004100041000410004, 0.0016400164001640015, 0.004920049200492005, 0.0008200082000820008, 0.0004100041000410004, 0.0004100041000410004, 0.0008200082000820008, 0.0012300123001230013, 0.0, 0.0008200082000820008, 0.0004100041000410004, 0.0, 0.0004100041000410004, 0.0008200082000820008, 0.0004100041000410004, 0.0, 0.0016400164001640015, 0.0008200082000820008, 0.0004100041000410004, 0.0016400164001640015, 0.0008200082000820008, 0.0, 0.0016400164001640015, 0.0008200082000820008, 0.0004100041000410004, 0.0, 0.0, 0.0, 0.0004100041000410004, 0.0012300123001230013, 0.0008200082000820008, 0.0, 0.0004100041000410004, 0.0012300123001230013, 0.0, 0.0, 0.0, 0.002870028700287003, 0.0008200082000820008, 0.0004100041000410004, 0.0, 0.0, 0.0, 0.0008200082000820008, 0.0008200082000820008, 0.0016400164001640015, 0.0, 0.0, 0.002870028700287003, 0.0008200082000820008, 0.0008200082000820008, 0.0004100041000410004, 0.0, 0.0, 0.0004100041000410004, 0.0016400164001640015, 0.0004100041000410004, 0.0016400164001640015, 0.002050020500205002, 0.0012300123001230013, 0.0016400164001640015, 0.0008200082000820008, 0.0008200082000820008, 0.0, 0.0, 0.0004100041000410004, 0.0008200082000820008, 0.0012300123001230013, 0.0, 0.0, 0.0, 0.0, 0.0004100041000410004, 0.0004100041000410004, 0.0012300123001230013, 0.0, 0.0, 0.0, 0.0008200082000820008, 0.0004100041000410004, 0.0008200082000820008, 0.0012300123001230013, 0.0004100041000410004, 0.0004100041000410004, 0.0008200082000820008, 0.0004100041000410004, 0.0004100041000410004, 0.0, 0.0012300123001230013, 0.0016400164001640015, 0.0, 0.0004100041000410004, 0.0, 0.0008200082000820008, 0.0008200082000820008, 0.0, 0.0008200082000820008, 0.0016400164001640015, 0.0004100041000410004, 0.0, 0.0, 0.0, 0.0004100041000410004, 0.0004100041000410004, 0.0008200082000820008, 0.0, 0.0, 0.0004100041000410004, 0.0, 0.002050020500205002, 0.0, 0.0008200082000820008, 0.0008200082000820008, 0.0004100041000410004, 0.0004100041000410004, 0.0, 0.0004100041000410004, 0.002050020500205002, 0.0004100041000410004, 0.0004100041000410004, 0.0004100041000410004, 0.0004100041000410004, 0.0, 0.0, 0.0008200082000820008, 0.0004100041000410004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0004100041000410004, 0.0, 0.0016400164001640015, 0.0004100041000410004, 0.0016400164001640015, 0.0, 0.0004100041000410004, 0.0, 0.0, 0.0, 0.0, 0.0004100041000410004, 0.0, 0.0, 0.0012300123001230013, 0.0004100041000410004, 0.0, 0.0004100041000410004, 0.0, 0.0008200082000820008, 0.0, 0.0008200082000820008, 0.0008200082000820008, 0.0, 0.0004100041000410004, 0.0004100041000410004, 0.0004100041000410004, 0.0, 0.0, 0.002050020500205002, 0.0, 0.0, 0.0, 0.0004100041000410004, 0.0024600246002460025, 0.0, 0.0, 0.0012300123001230013, 0.0004100041000410004, 0.0, 0.0, 0.0004100041000410004, 0.0008200082000820008, 0.0, 0.002870028700287003, 0.0008200082000820008, 0.0004100041000410004, 0.002050020500205002, 0.0016400164001640015, 0.0004100041000410004, 0.0004100041000410004, 0.0008200082000820008, 0.0004100041000410004, 0.0, 0.0004100041000410004, 0.0, 0.0, 0.0004100041000410004, 0.0004100041000410004, 0.0016400164001640015, 0.0004100041000410004, 0.0008200082000820008, 0.0012300123001230013, 0.0008200082000820008, 0.0, 0.0, 0.0, 0.0016400164001640015, 0.0, 0.0, 0.0, 0.0012300123001230013, 0.0, 0.0, 0.0, 0.0008200082000820008, 0.0008200082000820008, 0.0, 0.0, 0.0004100041000410004, 0.0008200082000820008, 0.0008200082000820008, 0.0004100041000410004, 0.0, 0.0, 0.0004100041000410004, 0.0004100041000410004, 0.0008200082000820008, 0.002870028700287003, 0.0, 0.0012300123001230013, 0.0, 0.0012300123001230013, 0.0004100041000410004, 0.0012300123001230013, 0.0, 0.0, 0.0004100041000410004, 0.0004100041000410004, 0.0, 0.0, 0.0, 0.0, 0.0016400164001640015, 0.0008200082000820008, 0.0, 0.0, 0.0, 0.0016400164001640015, 0.0, 0.0012300123001230013, 0.0008200082000820008, 0.0, 0.0, 0.0, 0.0, 0.0004100041000410004, 0.0004100041000410004, 0.0, 0.0004100041000410004, 0.0012300123001230013, 0.0, 0.004510045100451004, 0.0004100041000410004, 0.0012300123001230013, 0.0008200082000820008, 0.0, 0.0, 0.0012300123001230013, 0.0008200082000820008, 0.0, 0.0, 0.0, 0.0008200082000820008, 0.0, 0.0, 0.0, 0.0012300123001230013, 0.0008200082000820008, 0.0, 0.0012300123001230013, 0.0, 0.0004100041000410004, 0.0004100041000410004, 0.0012300123001230013, 0.0, 0.0008200082000820008, 0.0004100041000410004, 0.0, 0.0008200082000820008, 0.0012300123001230013, 0.0, 0.0008200082000820008, 0.0004100041000410004, 0.0, 0.0, 0.0, 0.0008200082000820008, 0.0004100041000410004, 0.0, 0.0008200082000820008, 0.0004100041000410004, 0.0008200082000820008, 0.002050020500205002, 0.0, 0.0008200082000820008, 0.0, 0.0008200082000820008, 0.0, 0.0, 0.0, 0.0, 0.0012300123001230013, 0.0008200082000820008, 0.0008200082000820008, 0.0004100041000410004, 0.0004100041000410004, 0.0, 0.0004100041000410004, 0.0, 0.0, 0.0, 0.0, 0.0012300123001230013, 0.0, 0.0, 0.0, 0.0008200082000820008, 0.0012300123001230013, 0.0, 0.002050020500205002, 0.0008200082000820008, 0.0008200082000820008, 0.0, 0.0004100041000410004, 0.0004100041000410004, 0.0004100041000410004, 0.0, 0.0, 0.0008200082000820008, 0.0, 0.0, 0.0004100041000410004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0016400164001640015, 0.0008200082000820008, 0.0008200082000820008, 0.0, 0.0012300123001230013, 0.0004100041000410004, 0.0, 0.0008200082000820008, 0.0024600246002460025, 0.0024600246002460025, 0.0008200082000820008, 0.0, 0.0012300123001230013, 0.0, 0.0004100041000410004, 0.0, 0.0004100041000410004, 0.0, 0.0012300123001230013, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0004100041000410004, 0.0012300123001230013, 0.0, 0.0008200082000820008, 0.0004100041000410004, 0.0016400164001640015, 0.002870028700287003, 0.0012300123001230013, 0.0008200082000820008, 0.0004100041000410004, 0.0016400164001640015, 0.0012300123001230013, 0.0, 0.0, 0.002050020500205002, 0.0, 0.0008200082000820008, 0.0004100041000410004, 0.0, 0.0004100041000410004, 0.0, 0.0, 0.0, 0.0, 0.0008200082000820008, 0.0008200082000820008, 0.0, 0.0004100041000410004, 0.0, 0.0004100041000410004, 0.0, 0.0, 0.0004100041000410004, 0.0, 0.0004100041000410004, 0.0004100041000410004, 0.0004100041000410004, 0.0, 0.0, 0.0, 0.0012300123001230013, 0.0004100041000410004, 0.0, 0.0004100041000410004, 0.0, 0.0008200082000820008, 0.0, 0.0, 0.0, 0.0012300123001230013, 0.0, 0.0, 0.0004100041000410004, 0.0004100041000410004, 0.0, 0.0, 0.0, 0.0008200082000820008, 0.0, 0.0008200082000820008, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0004100041000410004, 0.0, 0.0016400164001640015, 0.0, 0.0, 0.0, 0.0, 0.0008200082000820008, 0.0004100041000410004, 0.0, 0.0004100041000410004, 0.0, 0.0004100041000410004, 0.0, 0.0004100041000410004, 0.0, 0.0004100041000410004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0008200082000820008, 0.0, 0.0, 0.0, 0.0, 0.0008200082000820008, 0.0, 0.0, 0.0, 0.0, 0.0004100041000410004, 0.0, 0.0, 0.0, 0.0008200082000820008, 0.0004100041000410004, 0.0, 0.0012300123001230013, 0.0, 0.0008200082000820008, 0.0008200082000820008, 0.0, 0.0004100041000410004, 0.0, 0.0, 0.0008200082000820008, 0.0004100041000410004, 0.0004100041000410004, 0.0, 0.0, 0.0004100041000410004, 0.0, 0.0, 0.0004100041000410004, 0.0, 0.0, 0.0, 0.0, 0.0012300123001230013, 0.0004100041000410004], \"num_examples\": 2439.0}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"Address\", \"mask\": [\"<OOD>\", \"Punak\", \"West Ferdows Boulevard\", \"Shahran\", \"Shahr-e-Ziba\", \"Southern Janatabad\", \"Central Janatabad\", \"East Ferdows Boulevard\", \"Islamshahr\", \"Ekhtiarieh\", \"Feiz Garden\", \"Pakdasht\", \"North Program Organization\", \"Northern Janatabad\", \"Narmak\", \"Qasr-od-Dasht\", \"Tenant\", \"Southern Program Organization\", \"Beryanak\", \"Aqdasieh\", \"Abazar\"]}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.007, 0.002, 0.0, 0.005, 0.005, 0.0, 0.011, 0.0, 0.003, 0.008, 0.005, 0.0, 0.002, 0.004, 0.0, 0.002, 0.003, 0.003, 0.0, 0.011, 0.007, 0.001, 0.0, 0.0, 0.0, 0.0, 0.002, 0.01, 0.002, 0.017, 0.001, 0.004, 0.01, 0.001, 0.0, 0.015, 0.002, 0.007, 0.002, 0.0, 0.001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001, 0.019, 0.007, 0.004, 0.008, 0.014, 0.023, 0.009, 0.004, 0.001, 0.005, 0.0, 0.001, 0.003, 0.0, 0.001, 0.0, 0.0, 0.0, 0.006, 0.01, 0.008, 0.0, 0.019, 0.002, 0.003, 0.004, 0.002, 0.0, 0.0, 0.0, 0.008, 0.005, 0.0, 0.0, 0.006, 0.0, 0.001, 0.001, 0.0, 0.0, 0.0, 0.002, 0.005, 0.0, 0.0, 0.0, 0.008, 0.002, 0.0, 0.0, 0.002, 0.0, 0.0, 0.0, 0.0, 0.005, 0.005, 0.001, 0.0, 0.0, 0.0, 0.002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01, 0.0, 0.0, 0.001, 0.001, 0.0, 0.0, 0.002, 0.0, 0.006, 0.0, 0.002, 0.0, 0.001, 0.002, 0.012, 0.005, 0.0, 0.0, 0.002, 0.0, 0.0, 0.002, 0.0, 0.004, 0.0, 0.002, 0.002, 0.0, 0.0, 0.001, 0.0, 0.0, 0.003, 0.0, 0.0, 0.0, 0.001, 0.0, 0.006, 0.003, 0.001, 0.002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002, 0.0, 0.001, 0.002, 0.015, 0.005, 0.008, 0.009, 0.0, 0.002, 0.0, 0.0, 0.015, 0.0, 0.0, 0.002, 0.0, 0.007, 0.002, 0.01, 0.003, 0.001, 0.002, 0.0, 0.012, 0.008, 0.002, 0.0, 0.001, 0.0, 0.001, 0.003, 0.002, 0.009, 0.003, 0.002, 0.008, 0.01, 0.007, 0.0, 0.0, 0.003, 0.0, 0.005, 0.0, 0.008, 0.0, 0.002, 0.0, 0.009, 0.001, 0.005, 0.006, 0.0, 0.0, 0.0, 0.0, 0.002, 0.0, 0.0, 0.001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.003, 0.02, 0.003, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001, 0.0, 0.0, 0.0, 0.001, 0.01, 0.0, 0.0, 0.0, 0.002, 0.0, 0.0, 0.003, 0.002, 0.001, 0.0, 0.0, 0.0, 0.0, 0.002, 0.002, 0.0, 0.0, 0.0, 0.001, 0.003, 0.0, 0.0, 0.002, 0.0, 0.0, 0.0, 0.0, 0.002, 0.002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001, 0.002, 0.002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002, 0.0, 0.0, 0.002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001, 0.004, 0.001, 0.001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001, 0.0, 0.018, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002, 0.0, 0.0, 0.0, 0.003, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001, 0.007, 0.0, 0.0, 0.004, 0.001, 0.0, 0.002, 0.0, 0.0, 0.0, 0.003, 0.0, 0.0, 0.0, 0.0, 0.0, 0.006, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002, 0.0, 0.0, 0.0, 0.01, 0.0, 0.0, 0.0, 0.001, 0.004, 0.002, 0.0, 0.0, 0.0, 0.0, 0.001, 0.0, 0.0, 0.001, 0.0, 0.0, 0.0, 0.0, 0.002, 0.002, 0.004, 0.0, 0.002, 0.0, 0.0, 0.0, 0.0, 0.001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002, 0.001, 0.0, 0.002, 0.0, 0.002, 0.0, 0.0, 0.002, 0.001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002, 0.001, 0.0, 0.0, 0.002, 0.001, 0.002, 0.0, 0.0, 0.002, 0.001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001, 0.0, 0.0, 0.0, 0.0, 0.002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002, 0.0, 0.001, 0.0, 0.0, 0.001, 0.0, 0.0, 0.003, 0.003, 0.003, 0.0, 0.0, 0.002, 0.0, 0.0, 0.0, 0.0, 0.002, 0.0, 0.0, 0.0, 0.0, 0.001, 0.0, 0.003, 0.0, 0.0, 0.0, 0.0, 0.001, 0.0, 0.001, 0.001, 0.0, 0.002, 0.0, 0.0, 0.0, 0.0, 0.002, 0.0, 0.001, 0.0, 0.0, 0.002, 0.0, 0.002, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001, 0.0, 0.0, 0.001, 0.001, 0.0, 0.0, 0.0, 0.0, 0.001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001, 0.0, 0.0, 0.001, 0.0, 0.0, 0.001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002, 0.0, 0.0, 0.001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001, 0.0, 0.0, 0.0, 0.0, 0.001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.006, 0.001, 0.0, 0.002, 0.0, 0.001, 0.001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001, 0.0, 0.004, 0.0, 0.002, 0.003, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.003, 0.0, 0.0, 0.0, 0.002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002, 0.001, 0.0, 0.003, 0.0, 0.001, 0.0, 0.001, 0.0, 0.0, 0.001, 0.001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003, 0.0, 0.0, 0.003, 0.0, 0.0, 0.001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002, 0.0, 0.002, 0.0, 0.0, 0.0, 0.0, 0.001, 0.0, 0.0, 0.001, 0.001, 0.001, 0.0, 0.0, 0.002, 0.0, 0.002, 0.0, 0.0, 0.0, 0.0, 0.003, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003, 0.002, 0.002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001, 0.0, 0.002, 0.0, 0.0, 0.0, 0.0, 0.003, 0.0, 0.0, 0.005, 0.0, 0.0, 0.0, 0.0, 0.001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001, 0.001, 0.0, 0.0, 0.0, 0.0, 0.001, 0.0, 0.001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001, 0.0, 0.003, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001, 0.0, 0.001, 0.0, 0.001, 0.0, 0.0, 0.0, 0.001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002, 0.0, 0.0, 0.0, 0.0, 0.001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002, 0.001, 0.001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001], \"num_examples\": 1000.0}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"Area\", \"mask\": [\"75\", \"100\", \"90\", \"105\", \"60\", \"65\", \"80\", \"85\", \"110\", \"70\", \"87\", \"86\", \"72\", \"66\", \"145\", \"71\", \"92\", \"83\", \"76\", \"57\", \"98\", \"97\", \"84\", \"82\", \"160\", \"94\", \"74\", \"64\", \"170\", \"108\", \"93\", \"67\", \"96\", \"73\", \"48\", \"40\", \"106\", \"113\", \"101\", \"89\"]}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.0018083182640144665, 0.0, 0.0, 0.003616636528028933, 0.003616636528028933, 0.0, 0.0108499095840868, 0.0, 0.0054249547920434, 0.012658227848101266, 0.003616636528028933, 0.0, 0.0, 0.0018083182640144665, 0.0, 0.0, 0.0, 0.0, 0.0, 0.012658227848101266, 0.0108499095840868, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003616636528028933, 0.014466546112115732, 0.0018083182640144665, 0.0018083182640144665, 0.0018083182640144665, 0.003616636528028933, 0.018083182640144666, 0.0, 0.0, 0.012658227848101266, 0.0, 0.007233273056057866, 0.0018083182640144665, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03074141048824593, 0.0, 0.007233273056057866, 0.012658227848101266, 0.02531645569620253, 0.028933092224231464, 0.014466546112115732, 0.0, 0.0, 0.003616636528028933, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0108499095840868, 0.012658227848101266, 0.012658227848101266, 0.0, 0.0162748643761302, 0.003616636528028933, 0.0054249547920434, 0.003616636528028933, 0.003616636528028933, 0.0, 0.0, 0.0, 0.009041591320072333, 0.009041591320072333, 0.0, 0.0, 0.0, 0.0, 0.0018083182640144665, 0.0, 0.0, 0.0, 0.0, 0.0, 0.009041591320072333, 0.0, 0.0, 0.0, 0.014466546112115732, 0.003616636528028933, 0.0, 0.0, 0.003616636528028933, 0.0, 0.0, 0.0, 0.0, 0.0018083182640144665, 0.009041591320072333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0108499095840868, 0.0, 0.0, 0.0, 0.0018083182640144665, 0.0, 0.0, 0.0, 0.0, 0.0054249547920434, 0.0, 0.003616636528028933, 0.0, 0.0, 0.0, 0.018083182640144666, 0.003616636528028933, 0.0, 0.0, 0.003616636528028933, 0.0, 0.0, 0.003616636528028933, 0.0, 0.007233273056057866, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0018083182640144665, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0108499095840868, 0.0, 0.0, 0.003616636528028933, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003616636528028933, 0.0, 0.0018083182640144665, 0.0, 0.0162748643761302, 0.003616636528028933, 0.0054249547920434, 0.012658227848101266, 0.0, 0.0, 0.0, 0.0, 0.019891500904159132, 0.0, 0.0, 0.0018083182640144665, 0.0, 0.009041591320072333, 0.003616636528028933, 0.0108499095840868, 0.0054249547920434, 0.0, 0.003616636528028933, 0.0, 0.007233273056057866, 0.007233273056057866, 0.003616636528028933, 0.0, 0.0, 0.0, 0.0018083182640144665, 0.0, 0.003616636528028933, 0.0108499095840868, 0.0054249547920434, 0.0, 0.014466546112115732, 0.012658227848101266, 0.0, 0.0, 0.0, 0.0054249547920434, 0.0, 0.009041591320072333, 0.0, 0.009041591320072333, 0.0, 0.003616636528028933, 0.0, 0.0, 0.0, 0.009041591320072333, 0.0054249547920434, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003616636528028933, 0.0325497287522604, 0.0, 0.0, 0.0, 0.0, 0.007233273056057866, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0162748643761302, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003616636528028933, 0.0018083182640144665, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003616636528028933, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0018083182640144665, 0.0, 0.003616636528028933, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0018083182640144665, 0.0, 0.0, 0.003616636528028933, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0018083182640144665, 0.003616636528028933, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02531645569620253, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0054249547920434, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0018083182640144665, 0.0108499095840868, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003616636528028933, 0.0, 0.0, 0.0, 0.0018083182640144665, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007233273056057866, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007233273056057866, 0.0, 0.0, 0.0, 0.0018083182640144665, 0.0018083182640144665, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003616636528028933, 0.0, 0.0, 0.0, 0.003616636528028933, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0018083182640144665, 0.0, 0.003616636528028933, 0.0, 0.0018083182640144665, 0.0, 0.0, 0.0018083182640144665, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0018083182640144665, 0.0, 0.003616636528028933, 0.0, 0.0, 0.0, 0.0018083182640144665, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0018083182640144665, 0.0, 0.0, 0.0018083182640144665, 0.0, 0.0, 0.003616636528028933, 0.0054249547920434, 0.0054249547920434, 0.0, 0.0, 0.003616636528028933, 0.0, 0.0, 0.0, 0.0, 0.003616636528028933, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003616636528028933, 0.0, 0.0, 0.0, 0.0, 0.0018083182640144665, 0.0, 0.0, 0.0018083182640144665, 0.0, 0.003616636528028933, 0.0, 0.0, 0.0, 0.0, 0.003616636528028933, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007233273056057866, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0018083182640144665, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0018083182640144665, 0.0, 0.0, 0.0018083182640144665, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0018083182640144665, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0018083182640144665, 0.0, 0.0, 0.0018083182640144665, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0018083182640144665, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0018083182640144665, 0.0, 0.0, 0.0, 0.0, 0.0018083182640144665, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0054249547920434, 0.0018083182640144665, 0.0, 0.003616636528028933, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0018083182640144665, 0.0, 0.003616636528028933, 0.0, 0.003616636528028933, 0.0054249547920434, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0054249547920434, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003616636528028933, 0.0, 0.0, 0.003616636528028933, 0.0, 0.0018083182640144665, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0054249547920434, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0018083182640144665, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003616636528028933, 0.0, 0.0, 0.0, 0.0, 0.0018083182640144665, 0.0, 0.0, 0.0, 0.0, 0.0018083182640144665, 0.0, 0.0, 0.003616636528028933, 0.0, 0.0018083182640144665, 0.0, 0.0, 0.0, 0.0, 0.0054249547920434, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003616636528028933, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0018083182640144665, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0054249547920434, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0018083182640144665, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0018083182640144665, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0054249547920434, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0018083182640144665, 0.0, 0.0018083182640144665, 0.0, 0.0, 0.0, 0.0018083182640144665, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0018083182640144665, 0.0018083182640144665, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], \"num_examples\": 553.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"Price(USD)\", \"threshold\": 95833.3359375}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.0, 0.0, 0.0, 0.007272727272727273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0036363636363636364, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02909090909090909, 0.0, 0.0, 0.0036363636363636364, 0.0, 0.03636363636363636, 0.0, 0.0, 0.025454545454545455, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06181818181818182, 0.0, 0.0, 0.025454545454545455, 0.0, 0.05818181818181818, 0.02909090909090909, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02181818181818182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007272727272727273, 0.0, 0.0, 0.0, 0.0, 0.01818181818181818, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01818181818181818, 0.0, 0.0, 0.0, 0.02909090909090909, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02181818181818182, 0.0, 0.0, 0.0, 0.0036363636363636364, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007272727272727273, 0.0, 0.0, 0.0, 0.0, 0.014545454545454545, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02181818181818182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03272727272727273, 0.007272727272727273, 0.01090909090909091, 0.025454545454545455, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0036363636363636364, 0.0, 0.01818181818181818, 0.007272727272727273, 0.02181818181818182, 0.01090909090909091, 0.0, 0.007272727272727273, 0.0, 0.014545454545454545, 0.014545454545454545, 0.007272727272727273, 0.0, 0.0, 0.0, 0.0036363636363636364, 0.0, 0.007272727272727273, 0.0, 0.0, 0.0, 0.02909090909090909, 0.0, 0.0, 0.0, 0.0, 0.01090909090909091, 0.0, 0.01818181818181818, 0.0, 0.01818181818181818, 0.0, 0.007272727272727273, 0.0, 0.0, 0.0, 0.01818181818181818, 0.01090909090909091, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007272727272727273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03272727272727273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0036363636363636364, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007272727272727273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01090909090909091, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0036363636363636364, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0036363636363636364, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0036363636363636364, 0.0036363636363636364, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007272727272727273, 0.0, 0.0, 0.0, 0.007272727272727273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0036363636363636364, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0036363636363636364, 0.0, 0.0, 0.0036363636363636364, 0.0, 0.0, 0.007272727272727273, 0.01090909090909091, 0.01090909090909091, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0036363636363636364, 0.0, 0.0, 0.0036363636363636364, 0.0, 0.007272727272727273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.014545454545454545, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0036363636363636364, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0036363636363636364, 0.0, 0.0, 0.0036363636363636364, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0036363636363636364, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0036363636363636364, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0036363636363636364, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007272727272727273, 0.0, 0.007272727272727273, 0.01090909090909091, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007272727272727273, 0.0, 0.0, 0.007272727272727273, 0.0, 0.0036363636363636364, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01090909090909091, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0036363636363636364, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0036363636363636364, 0.0, 0.0036363636363636364, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0036363636363636364, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], \"num_examples\": 275.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"Price(USD)\", \"threshold\": 121166.671875}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.0035971223021582736, 0.0, 0.0, 0.0, 0.007194244604316547, 0.0, 0.02158273381294964, 0.0, 0.01079136690647482, 0.025179856115107913, 0.007194244604316547, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.025179856115107913, 0.02158273381294964, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007194244604316547, 0.0, 0.0035971223021582736, 0.0035971223021582736, 0.0, 0.007194244604316547, 0.0, 0.0, 0.0, 0.0, 0.0, 0.014388489208633094, 0.0035971223021582736, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.014388489208633094, 0.0, 0.050359712230215826, 0.0, 0.0, 0.0, 0.0, 0.007194244604316547, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.025179856115107913, 0.025179856115107913, 0.0, 0.03237410071942446, 0.007194244604316547, 0.01079136690647482, 0.0, 0.007194244604316547, 0.0, 0.0, 0.0, 0.0, 0.017985611510791366, 0.0, 0.0, 0.0, 0.0, 0.0035971223021582736, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007194244604316547, 0.0, 0.0, 0.007194244604316547, 0.0, 0.0, 0.0, 0.0, 0.0035971223021582736, 0.017985611510791366, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01079136690647482, 0.0, 0.007194244604316547, 0.0, 0.0, 0.0, 0.03597122302158273, 0.007194244604316547, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007194244604316547, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0035971223021582736, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007194244604316547, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007194244604316547, 0.0, 0.0035971223021582736, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.039568345323741004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02158273381294964, 0.01079136690647482, 0.0, 0.0, 0.025179856115107913, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06474820143884892, 0.0, 0.0, 0.0, 0.0, 0.014388489208633094, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007194244604316547, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007194244604316547, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0035971223021582736, 0.0, 0.007194244604316547, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0035971223021582736, 0.0, 0.0, 0.007194244604316547, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0035971223021582736, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.050359712230215826, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02158273381294964, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007194244604316547, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.014388489208633094, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.014388489208633094, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0035971223021582736, 0.0, 0.007194244604316547, 0.0, 0.0035971223021582736, 0.0, 0.0, 0.0035971223021582736, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0035971223021582736, 0.0, 0.007194244604316547, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007194244604316547, 0.0, 0.0, 0.0, 0.0, 0.007194244604316547, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007194244604316547, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007194244604316547, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0035971223021582736, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0035971223021582736, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0035971223021582736, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01079136690647482, 0.0035971223021582736, 0.0, 0.007194244604316547, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0035971223021582736, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01079136690647482, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0035971223021582736, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007194244604316547, 0.0, 0.0, 0.0, 0.0, 0.0035971223021582736, 0.0, 0.0, 0.0, 0.0, 0.0035971223021582736, 0.0, 0.0, 0.007194244604316547, 0.0, 0.0035971223021582736, 0.0, 0.0, 0.0, 0.0, 0.01079136690647482, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007194244604316547, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0035971223021582736, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01079136690647482, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0035971223021582736, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01079136690647482, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0035971223021582736, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0035971223021582736, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], \"num_examples\": 278.0}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"Address\", \"mask\": [\"Punak\", \"West Ferdows Boulevard\", \"Shahran\", \"Shahr-e-Ziba\", \"Southern Janatabad\", \"Central Janatabad\", \"Feiz Garden\"]}}]}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.013422818791946308, 0.0044742729306487695, 0.0, 0.006711409395973154, 0.006711409395973154, 0.0, 0.011185682326621925, 0.0, 0.0, 0.0022371364653243847, 0.006711409395973154, 0.0, 0.0044742729306487695, 0.006711409395973154, 0.0, 0.0044742729306487695, 0.006711409395973154, 0.006711409395973154, 0.0, 0.008948545861297539, 0.0022371364653243847, 0.0022371364653243847, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0044742729306487695, 0.0022371364653243847, 0.035794183445190156, 0.0, 0.0044742729306487695, 0.0, 0.0022371364653243847, 0.0, 0.017897091722595078, 0.0044742729306487695, 0.006711409395973154, 0.0022371364653243847, 0.0, 0.0022371364653243847, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0022371364653243847, 0.0044742729306487695, 0.015659955257270694, 0.0, 0.0022371364653243847, 0.0, 0.015659955257270694, 0.0022371364653243847, 0.008948545861297539, 0.0022371364653243847, 0.006711409395973154, 0.0, 0.0022371364653243847, 0.006711409395973154, 0.0, 0.0022371364653243847, 0.0, 0.0, 0.0, 0.0, 0.006711409395973154, 0.0022371364653243847, 0.0, 0.02237136465324385, 0.0, 0.0, 0.0044742729306487695, 0.0, 0.0, 0.0, 0.0, 0.006711409395973154, 0.0, 0.0, 0.0, 0.013422818791946308, 0.0, 0.0, 0.0022371364653243847, 0.0, 0.0, 0.0, 0.0044742729306487695, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008948545861297539, 0.0, 0.0022371364653243847, 0.0, 0.0, 0.0, 0.0044742729306487695, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008948545861297539, 0.0, 0.0, 0.0022371364653243847, 0.0, 0.0, 0.0, 0.0044742729306487695, 0.0, 0.006711409395973154, 0.0, 0.0, 0.0, 0.0022371364653243847, 0.0044742729306487695, 0.0044742729306487695, 0.006711409395973154, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0044742729306487695, 0.0044742729306487695, 0.0, 0.0, 0.0, 0.0, 0.0, 0.006711409395973154, 0.0, 0.0, 0.0, 0.0022371364653243847, 0.0, 0.0, 0.006711409395973154, 0.0022371364653243847, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0044742729306487695, 0.013422818791946308, 0.006711409395973154, 0.011185682326621925, 0.0044742729306487695, 0.0, 0.0044742729306487695, 0.0, 0.0, 0.008948545861297539, 0.0, 0.0, 0.0022371364653243847, 0.0, 0.0044742729306487695, 0.0, 0.008948545861297539, 0.0, 0.0022371364653243847, 0.0, 0.0, 0.017897091722595078, 0.008948545861297539, 0.0, 0.0, 0.0022371364653243847, 0.0, 0.0, 0.006711409395973154, 0.0, 0.006711409395973154, 0.0, 0.0044742729306487695, 0.0, 0.006711409395973154, 0.015659955257270694, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.006711409395973154, 0.0, 0.0, 0.0, 0.020134228187919462, 0.0022371364653243847, 0.0, 0.006711409395973154, 0.0, 0.0, 0.0, 0.0, 0.0044742729306487695, 0.0, 0.0, 0.0022371364653243847, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008948545861297539, 0.0022371364653243847, 0.0044742729306487695, 0.006711409395973154, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0022371364653243847, 0.0, 0.0, 0.0, 0.0022371364653243847, 0.0022371364653243847, 0.0, 0.0, 0.0, 0.0044742729306487695, 0.0, 0.0, 0.006711409395973154, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0044742729306487695, 0.0044742729306487695, 0.0, 0.0, 0.0, 0.0022371364653243847, 0.0022371364653243847, 0.0, 0.0, 0.0044742729306487695, 0.0, 0.0, 0.0, 0.0, 0.0044742729306487695, 0.0044742729306487695, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0044742729306487695, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0022371364653243847, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0044742729306487695, 0.0022371364653243847, 0.0022371364653243847, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0022371364653243847, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0022371364653243847, 0.0, 0.008948545861297539, 0.0, 0.0, 0.0, 0.0, 0.008948545861297539, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015659955257270694, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0022371364653243847, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0044742729306487695, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0022371364653243847, 0.0, 0.0, 0.008948545861297539, 0.0022371364653243847, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0044742729306487695, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0044742729306487695, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0044742729306487695, 0.0, 0.0, 0.0, 0.013422818791946308, 0.0, 0.0, 0.0, 0.0, 0.006711409395973154, 0.0044742729306487695, 0.0, 0.0, 0.0, 0.0, 0.0022371364653243847, 0.0, 0.0, 0.0022371364653243847, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0044742729306487695, 0.008948545861297539, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0022371364653243847, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0044742729306487695, 0.0, 0.0, 0.0, 0.0, 0.0022371364653243847, 0.0, 0.0, 0.0022371364653243847, 0.0022371364653243847, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0044742729306487695, 0.0022371364653243847, 0.0, 0.0, 0.0022371364653243847, 0.0022371364653243847, 0.0, 0.0, 0.0, 0.0044742729306487695, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.006711409395973154, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0022371364653243847, 0.0, 0.0, 0.0, 0.0, 0.0044742729306487695, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0044742729306487695, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0022371364653243847, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0022371364653243847, 0.0, 0.0022371364653243847, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0022371364653243847, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0022371364653243847, 0.0, 0.0, 0.0044742729306487695, 0.0, 0.0044742729306487695, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0022371364653243847, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0022371364653243847, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0044742729306487695, 0.0, 0.0, 0.0022371364653243847, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.006711409395973154, 0.0, 0.0, 0.0, 0.0, 0.0022371364653243847, 0.0022371364653243847, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0044742729306487695, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008948545861297539, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0044742729306487695, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0044742729306487695, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0022371364653243847, 0.0, 0.0022371364653243847, 0.0, 0.0, 0.0, 0.0022371364653243847, 0.0, 0.0, 0.0022371364653243847, 0.0022371364653243847, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0044742729306487695, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.011185682326621925, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.006711409395973154, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0044742729306487695, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0022371364653243847, 0.0022371364653243847, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0022371364653243847, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0022371364653243847, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.006711409395973154, 0.0044742729306487695, 0.0044742729306487695, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.006711409395973154, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0022371364653243847, 0.0, 0.0044742729306487695, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.011185682326621925, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0022371364653243847, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0022371364653243847, 0.0022371364653243847, 0.0, 0.0, 0.0, 0.0, 0.0022371364653243847, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0022371364653243847, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0022371364653243847, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0044742729306487695, 0.0, 0.0, 0.0, 0.0, 0.0022371364653243847, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0044742729306487695, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0022371364653243847], \"num_examples\": 447.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"Price(USD)\", \"threshold\": 107166.671875}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.0, 0.0, 0.0, 0.013392857142857142, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008928571428571428, 0.013392857142857142, 0.0, 0.008928571428571428, 0.0, 0.013392857142857142, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004464285714285714, 0.0, 0.03571428571428571, 0.008928571428571428, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03125, 0.0, 0.004464285714285714, 0.0, 0.03125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.013392857142857142, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008928571428571428, 0.0, 0.0, 0.0, 0.0, 0.013392857142857142, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004464285714285714, 0.0, 0.0, 0.0, 0.008928571428571428, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004464285714285714, 0.0, 0.0, 0.0, 0.008928571428571428, 0.0, 0.0, 0.0, 0.0, 0.0, 0.017857142857142856, 0.0, 0.0, 0.004464285714285714, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004464285714285714, 0.008928571428571428, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008928571428571428, 0.008928571428571428, 0.0, 0.0, 0.0, 0.0, 0.0, 0.013392857142857142, 0.0, 0.0, 0.0, 0.004464285714285714, 0.0, 0.0, 0.013392857142857142, 0.004464285714285714, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.013392857142857142, 0.022321428571428572, 0.008928571428571428, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004464285714285714, 0.0, 0.008928571428571428, 0.0, 0.017857142857142856, 0.0, 0.004464285714285714, 0.0, 0.0, 0.03571428571428571, 0.017857142857142856, 0.0, 0.0, 0.004464285714285714, 0.0, 0.0, 0.013392857142857142, 0.0, 0.0, 0.0, 0.008928571428571428, 0.0, 0.0, 0.03125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.013392857142857142, 0.0, 0.0, 0.0, 0.04017857142857143, 0.0, 0.0, 0.013392857142857142, 0.0, 0.0, 0.0, 0.0, 0.008928571428571428, 0.0, 0.0, 0.004464285714285714, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.017857142857142856, 0.004464285714285714, 0.0, 0.013392857142857142, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004464285714285714, 0.0, 0.0, 0.0, 0.0, 0.004464285714285714, 0.0, 0.0, 0.0, 0.008928571428571428, 0.0, 0.0, 0.013392857142857142, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008928571428571428, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008928571428571428, 0.008928571428571428, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008928571428571428, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008928571428571428, 0.004464285714285714, 0.004464285714285714, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004464285714285714, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004464285714285714, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.017857142857142856, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004464285714285714, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008928571428571428, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008928571428571428, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.013392857142857142, 0.008928571428571428, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004464285714285714, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008928571428571428, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004464285714285714, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008928571428571428, 0.004464285714285714, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.013392857142857142, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008928571428571428, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004464285714285714, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004464285714285714, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008928571428571428, 0.0, 0.008928571428571428, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004464285714285714, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004464285714285714, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004464285714285714, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008928571428571428, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008928571428571428, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004464285714285714, 0.0, 0.0, 0.0, 0.004464285714285714, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008928571428571428, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004464285714285714, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008928571428571428, 0.008928571428571428, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.013392857142857142, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022321428571428572, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004464285714285714, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004464285714285714, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004464285714285714, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008928571428571428, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], \"num_examples\": 224.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"Room\", \"threshold\": 2.5}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.026905829596412557, 0.008968609865470852, 0.0, 0.0, 0.013452914798206279, 0.0, 0.02242152466367713, 0.0, 0.0, 0.004484304932735426, 0.013452914798206279, 0.0, 0.0, 0.0, 0.0, 0.0, 0.013452914798206279, 0.0, 0.0, 0.017937219730941704, 0.004484304932735426, 0.004484304932735426, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008968609865470852, 0.004484304932735426, 0.07174887892376682, 0.0, 0.008968609865470852, 0.0, 0.0, 0.0, 0.0, 0.0, 0.013452914798206279, 0.004484304932735426, 0.0, 0.004484304932735426, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004484304932735426, 0.008968609865470852, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004484304932735426, 0.017937219730941704, 0.004484304932735426, 0.013452914798206279, 0.0, 0.004484304932735426, 0.0, 0.0, 0.004484304932735426, 0.0, 0.0, 0.0, 0.0, 0.013452914798206279, 0.004484304932735426, 0.0, 0.04484304932735426, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.026905829596412557, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.017937219730941704, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008968609865470852, 0.0, 0.013452914798206279, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008968609865470852, 0.013452914798206279, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008968609865470852, 0.026905829596412557, 0.0, 0.0, 0.0, 0.0, 0.008968609865470852, 0.0, 0.0, 0.017937219730941704, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.013452914798206279, 0.0, 0.0, 0.0, 0.013452914798206279, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004484304932735426, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008968609865470852, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004484304932735426, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008968609865470852, 0.0, 0.0, 0.0, 0.0, 0.004484304932735426, 0.004484304932735426, 0.0, 0.0, 0.008968609865470852, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004484304932735426, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.017937219730941704, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03139013452914798, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004484304932735426, 0.0, 0.0, 0.017937219730941704, 0.004484304932735426, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008968609865470852, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008968609865470852, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.026905829596412557, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004484304932735426, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.017937219730941704, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008968609865470852, 0.0, 0.0, 0.0, 0.0, 0.004484304932735426, 0.0, 0.0, 0.004484304932735426, 0.004484304932735426, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004484304932735426, 0.004484304932735426, 0.0, 0.0, 0.0, 0.008968609865470852, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004484304932735426, 0.0, 0.0, 0.0, 0.0, 0.008968609865470852, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004484304932735426, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004484304932735426, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004484304932735426, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008968609865470852, 0.0, 0.0, 0.004484304932735426, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.013452914798206279, 0.0, 0.0, 0.0, 0.0, 0.004484304932735426, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.017937219730941704, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008968609865470852, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004484304932735426, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004484304932735426, 0.004484304932735426, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02242152466367713, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.013452914798206279, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008968609865470852, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004484304932735426, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004484304932735426, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004484304932735426, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.013452914798206279, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004484304932735426, 0.0, 0.008968609865470852, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004484304932735426, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004484304932735426, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004484304932735426, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004484304932735426, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008968609865470852, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004484304932735426], \"num_examples\": 223.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"Price(USD)\", \"threshold\": 65500.0}}]}]}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.0020847810979847115, 0.011118832522585128, 0.0, 0.002779708130646282, 0.007644197359277276, 0.006254343293954135, 0.001389854065323141, 0.0, 0.0, 0.001389854065323141, 0.0006949270326615705, 0.0, 0.002779708130646282, 0.001389854065323141, 0.001389854065323141, 0.004864489228630994, 0.002779708130646282, 0.0, 0.0020847810979847115, 0.0034746351633078527, 0.0, 0.0, 0.0020847810979847115, 0.0006949270326615705, 0.0, 0.0020847810979847115, 0.0, 0.0006949270326615705, 0.0118137595552467, 0.001389854065323141, 0.0, 0.0, 0.0034746351633078527, 0.001389854065323141, 0.0, 0.002779708130646282, 0.0006949270326615705, 0.015983321751216122, 0.0006949270326615705, 0.0, 0.0, 0.001389854065323141, 0.0, 0.006949270326615705, 0.006254343293954135, 0.0, 0.0, 0.0, 0.004169562195969423, 0.004864489228630994, 0.007644197359277276, 0.001389854065323141, 0.005559416261292564, 0.0034746351633078527, 0.0, 0.007644197359277276, 0.002779708130646282, 0.009728978457261988, 0.004169562195969423, 0.004864489228630994, 0.0020847810979847115, 0.0, 0.0, 0.001389854065323141, 0.0034746351633078527, 0.0, 0.006254343293954135, 0.001389854065323141, 0.0, 0.001389854065323141, 0.001389854065323141, 0.0, 0.005559416261292564, 0.009034051424600417, 0.0, 0.0, 0.0006949270326615705, 0.007644197359277276, 0.004169562195969423, 0.0034746351633078527, 0.001389854065323141, 0.005559416261292564, 0.0, 0.0020847810979847115, 0.0020847810979847115, 0.005559416261292564, 0.0006949270326615705, 0.0006949270326615705, 0.004864489228630994, 0.0006949270326615705, 0.001389854065323141, 0.0020847810979847115, 0.001389854065323141, 0.009034051424600417, 0.010423905489923557, 0.0006949270326615705, 0.0, 0.0, 0.0020847810979847115, 0.0006949270326615705, 0.0006949270326615705, 0.0, 0.006254343293954135, 0.006949270326615705, 0.006254343293954135, 0.01389854065323141, 0.0006949270326615705, 0.0006949270326615705, 0.0006949270326615705, 0.0006949270326615705, 0.0, 0.002779708130646282, 0.0, 0.0, 0.002779708130646282, 0.0006949270326615705, 0.0, 0.009728978457261988, 0.0, 0.002779708130646282, 0.0006949270326615705, 0.001389854065323141, 0.0, 0.0, 0.001389854065323141, 0.0, 0.0006949270326615705, 0.001389854065323141, 0.004864489228630994, 0.001389854065323141, 0.0118137595552467, 0.0006949270326615705, 0.0020847810979847115, 0.0006949270326615705, 0.0020847810979847115, 0.0, 0.0, 0.0, 0.006949270326615705, 0.0, 0.0020847810979847115, 0.004169562195969423, 0.001389854065323141, 0.0, 0.0, 0.004864489228630994, 0.0006949270326615705, 0.0, 0.0006949270326615705, 0.011118832522585128, 0.006254343293954135, 0.0020847810979847115, 0.011118832522585128, 0.0, 0.0020847810979847115, 0.0, 0.0, 0.0020847810979847115, 0.0006949270326615705, 0.0006949270326615705, 0.0, 0.0034746351633078527, 0.001389854065323141, 0.001389854065323141, 0.0, 0.0, 0.0034746351633078527, 0.0034746351633078527, 0.0, 0.002779708130646282, 0.002779708130646282, 0.009728978457261988, 0.004864489228630994, 0.0006949270326615705, 0.0006949270326615705, 0.0, 0.0020847810979847115, 0.005559416261292564, 0.001389854065323141, 0.0, 0.0, 0.001389854065323141, 0.001389854065323141, 0.0, 0.004864489228630994, 0.0, 0.0, 0.0006949270326615705, 0.0020847810979847115, 0.002779708130646282, 0.0020847810979847115, 0.0020847810979847115, 0.002779708130646282, 0.0, 0.0, 0.0020847810979847115, 0.006254343293954135, 0.0, 0.0006949270326615705, 0.0, 0.0020847810979847115, 0.0, 0.0020847810979847115, 0.002779708130646282, 0.0020847810979847115, 0.0, 0.0, 0.0006949270326615705, 0.0, 0.0, 0.0034746351633078527, 0.0, 0.0, 0.0, 0.0020847810979847115, 0.0, 0.0, 0.0, 0.0020847810979847115, 0.0006949270326615705, 0.0006949270326615705, 0.0020847810979847115, 0.001389854065323141, 0.0034746351633078527, 0.0, 0.001389854065323141, 0.0006949270326615705, 0.0, 0.0, 0.0, 0.0006949270326615705, 0.0, 0.0006949270326615705, 0.001389854065323141, 0.0006949270326615705, 0.0034746351633078527, 0.0, 0.001389854065323141, 0.0, 0.002779708130646282, 0.0, 0.0, 0.0, 0.001389854065323141, 0.005559416261292564, 0.0, 0.0, 0.006254343293954135, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001389854065323141, 0.0, 0.0, 0.001389854065323141, 0.002779708130646282, 0.005559416261292564, 0.0, 0.0, 0.0, 0.0, 0.002779708130646282, 0.0, 0.0, 0.002779708130646282, 0.0, 0.0, 0.0, 0.0, 0.001389854065323141, 0.0, 0.0006949270326615705, 0.001389854065323141, 0.0006949270326615705, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005559416261292564, 0.0, 0.001389854065323141, 0.001389854065323141, 0.0006949270326615705, 0.0020847810979847115, 0.001389854065323141, 0.0, 0.0, 0.0, 0.002779708130646282, 0.001389854065323141, 0.0020847810979847115, 0.002779708130646282, 0.0, 0.0006949270326615705, 0.005559416261292564, 0.0006949270326615705, 0.0, 0.0006949270326615705, 0.0020847810979847115, 0.0, 0.0006949270326615705, 0.002779708130646282, 0.001389854065323141, 0.0, 0.0, 0.0, 0.0, 0.006949270326615705, 0.007644197359277276, 0.0, 0.0, 0.0006949270326615705, 0.002779708130646282, 0.0, 0.004169562195969423, 0.0, 0.0020847810979847115, 0.0, 0.0006949270326615705, 0.0, 0.0006949270326615705, 0.0, 0.0006949270326615705, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001389854065323141, 0.004864489228630994, 0.0020847810979847115, 0.0, 0.0, 0.0006949270326615705, 0.0020847810979847115, 0.001389854065323141, 0.0, 0.001389854065323141, 0.0, 0.001389854065323141, 0.001389854065323141, 0.0006949270326615705, 0.0, 0.0034746351633078527, 0.0006949270326615705, 0.0, 0.0006949270326615705, 0.0006949270326615705, 0.0020847810979847115, 0.0006949270326615705, 0.005559416261292564, 0.002779708130646282, 0.0, 0.004169562195969423, 0.0, 0.001389854065323141, 0.0006949270326615705, 0.0, 0.0, 0.0, 0.0006949270326615705, 0.001389854065323141, 0.0, 0.0006949270326615705, 0.0006949270326615705, 0.0, 0.001389854065323141, 0.0, 0.0006949270326615705, 0.0, 0.001389854065323141, 0.0006949270326615705, 0.0006949270326615705, 0.001389854065323141, 0.0020847810979847115, 0.0, 0.001389854065323141, 0.0006949270326615705, 0.004169562195969423, 0.010423905489923557, 0.0, 0.0006949270326615705, 0.0, 0.0, 0.0006949270326615705, 0.0, 0.0006949270326615705, 0.0006949270326615705, 0.002779708130646282, 0.0, 0.001389854065323141, 0.0006949270326615705, 0.002779708130646282, 0.0, 0.0006949270326615705, 0.0006949270326615705, 0.0020847810979847115, 0.0006949270326615705, 0.0, 0.0006949270326615705, 0.001389854065323141, 0.0, 0.0, 0.004169562195969423, 0.0020847810979847115, 0.0020847810979847115, 0.0, 0.0, 0.0020847810979847115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0020847810979847115, 0.002779708130646282, 0.001389854065323141, 0.0006949270326615705, 0.0, 0.0, 0.0, 0.0, 0.001389854065323141, 0.0034746351633078527, 0.002779708130646282, 0.0020847810979847115, 0.005559416261292564, 0.0, 0.0006949270326615705, 0.001389854065323141, 0.008339124391938846, 0.0, 0.0006949270326615705, 0.0006949270326615705, 0.0, 0.001389854065323141, 0.0, 0.001389854065323141, 0.0006949270326615705, 0.0, 0.0006949270326615705, 0.0, 0.0, 0.0, 0.002779708130646282, 0.0, 0.0, 0.001389854065323141, 0.001389854065323141, 0.0, 0.001389854065323141, 0.0006949270326615705, 0.0006949270326615705, 0.0, 0.0, 0.0, 0.0006949270326615705, 0.0, 0.001389854065323141, 0.0, 0.0006949270326615705, 0.0020847810979847115, 0.0, 0.0, 0.0, 0.004864489228630994, 0.0006949270326615705, 0.0006949270326615705, 0.0, 0.0, 0.0, 0.0, 0.001389854065323141, 0.002779708130646282, 0.0, 0.0, 0.004864489228630994, 0.0, 0.001389854065323141, 0.0, 0.0, 0.0, 0.0, 0.002779708130646282, 0.0006949270326615705, 0.0006949270326615705, 0.001389854065323141, 0.0, 0.002779708130646282, 0.001389854065323141, 0.0, 0.0, 0.0, 0.0006949270326615705, 0.001389854065323141, 0.0006949270326615705, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0006949270326615705, 0.0, 0.0, 0.0, 0.0, 0.001389854065323141, 0.0, 0.001389854065323141, 0.001389854065323141, 0.0, 0.0006949270326615705, 0.0, 0.0006949270326615705, 0.0006949270326615705, 0.0, 0.0020847810979847115, 0.001389854065323141, 0.0, 0.0, 0.0, 0.001389854065323141, 0.0, 0.0, 0.0, 0.0, 0.0006949270326615705, 0.0, 0.0, 0.0, 0.0006949270326615705, 0.0, 0.001389854065323141, 0.0, 0.0, 0.0006949270326615705, 0.0, 0.0034746351633078527, 0.0, 0.001389854065323141, 0.001389854065323141, 0.0006949270326615705, 0.0006949270326615705, 0.0, 0.0, 0.0034746351633078527, 0.0006949270326615705, 0.0, 0.0, 0.0006949270326615705, 0.0, 0.0, 0.001389854065323141, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002779708130646282, 0.0, 0.002779708130646282, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0006949270326615705, 0.0, 0.0, 0.0020847810979847115, 0.0, 0.0, 0.0006949270326615705, 0.0, 0.001389854065323141, 0.0, 0.001389854065323141, 0.0, 0.0, 0.0006949270326615705, 0.0, 0.0006949270326615705, 0.0, 0.0, 0.0034746351633078527, 0.0, 0.0, 0.0, 0.0, 0.004169562195969423, 0.0, 0.0, 0.0020847810979847115, 0.0, 0.0, 0.0, 0.0006949270326615705, 0.001389854065323141, 0.0, 0.0006949270326615705, 0.0006949270326615705, 0.0006949270326615705, 0.0020847810979847115, 0.002779708130646282, 0.0, 0.0, 0.001389854065323141, 0.0006949270326615705, 0.0, 0.0006949270326615705, 0.0, 0.0, 0.0, 0.0006949270326615705, 0.0, 0.0006949270326615705, 0.0, 0.0, 0.001389854065323141, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001389854065323141, 0.0, 0.0, 0.0006949270326615705, 0.001389854065323141, 0.0, 0.0006949270326615705, 0.0, 0.0, 0.0006949270326615705, 0.0006949270326615705, 0.0, 0.004169562195969423, 0.0, 0.0, 0.0, 0.001389854065323141, 0.0006949270326615705, 0.001389854065323141, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002779708130646282, 0.001389854065323141, 0.0, 0.0, 0.0, 0.002779708130646282, 0.0, 0.0020847810979847115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0006949270326615705, 0.0006949270326615705, 0.0, 0.0006949270326615705, 0.0020847810979847115, 0.0, 0.004169562195969423, 0.0006949270326615705, 0.0020847810979847115, 0.001389854065323141, 0.0, 0.0, 0.0020847810979847115, 0.001389854065323141, 0.0, 0.0, 0.0, 0.001389854065323141, 0.0, 0.0, 0.0, 0.0, 0.001389854065323141, 0.0, 0.0, 0.0, 0.0006949270326615705, 0.0, 0.0020847810979847115, 0.0, 0.001389854065323141, 0.0006949270326615705, 0.0, 0.001389854065323141, 0.0006949270326615705, 0.0, 0.0, 0.0006949270326615705, 0.0, 0.0, 0.0, 0.0006949270326615705, 0.0006949270326615705, 0.0, 0.0006949270326615705, 0.0, 0.0006949270326615705, 0.0034746351633078527, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001389854065323141, 0.001389854065323141, 0.0006949270326615705, 0.0006949270326615705, 0.0, 0.0006949270326615705, 0.0, 0.0, 0.0, 0.0, 0.0020847810979847115, 0.0, 0.0, 0.0, 0.0, 0.0020847810979847115, 0.0, 0.0034746351633078527, 0.001389854065323141, 0.001389854065323141, 0.0, 0.0, 0.0006949270326615705, 0.0006949270326615705, 0.0, 0.0, 0.001389854065323141, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0006949270326615705, 0.0, 0.0, 0.0, 0.0020847810979847115, 0.0006949270326615705, 0.0, 0.001389854065323141, 0.004169562195969423, 0.004169562195969423, 0.001389854065323141, 0.0, 0.0, 0.0, 0.0006949270326615705, 0.0, 0.0006949270326615705, 0.0, 0.0020847810979847115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0006949270326615705, 0.0020847810979847115, 0.0, 0.001389854065323141, 0.0, 0.002779708130646282, 0.0034746351633078527, 0.0020847810979847115, 0.001389854065323141, 0.0006949270326615705, 0.002779708130646282, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001389854065323141, 0.0006949270326615705, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001389854065323141, 0.001389854065323141, 0.0, 0.0, 0.0, 0.0006949270326615705, 0.0, 0.0, 0.0006949270326615705, 0.0, 0.0006949270326615705, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0020847810979847115, 0.0, 0.0, 0.0, 0.0, 0.001389854065323141, 0.0, 0.0, 0.0, 0.0020847810979847115, 0.0, 0.0, 0.0006949270326615705, 0.0006949270326615705, 0.0, 0.0, 0.0, 0.001389854065323141, 0.0, 0.001389854065323141, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0006949270326615705, 0.0, 0.0, 0.0, 0.0, 0.001389854065323141, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0006949270326615705, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001389854065323141, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001389854065323141, 0.0006949270326615705, 0.0, 0.0020847810979847115, 0.0, 0.001389854065323141, 0.001389854065323141, 0.0, 0.0006949270326615705, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0006949270326615705, 0.0, 0.0, 0.0006949270326615705, 0.0, 0.0, 0.0, 0.0, 0.0020847810979847115, 0.0], \"num_examples\": 1439.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"Price(USD)\", \"threshold\": 86250.0}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.0, 0.0, 0.0, 0.005563282336578581, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005563282336578581, 0.0027816411682892906, 0.0, 0.009735744089012517, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004172461752433936, 0.0013908205841446453, 0.0, 0.004172461752433936, 0.0, 0.0013908205841446453, 0.0, 0.0, 0.0, 0.0, 0.006954102920723227, 0.0027816411682892906, 0.0, 0.005563282336578581, 0.0013908205841446453, 0.0, 0.0013908205841446453, 0.0, 0.0, 0.0, 0.0, 0.0, 0.012517385257301807, 0.0, 0.0, 0.0, 0.008344923504867872, 0.0, 0.015299026425591099, 0.0027816411682892906, 0.011126564673157162, 0.006954102920723227, 0.0, 0.0, 0.0, 0.0, 0.0, 0.009735744089012517, 0.004172461752433936, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0027816411682892906, 0.0, 0.0, 0.0, 0.0, 0.011126564673157162, 0.0, 0.0, 0.0, 0.0, 0.015299026425591099, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004172461752433936, 0.0, 0.0013908205841446453, 0.0013908205841446453, 0.009735744089012517, 0.0013908205841446453, 0.0, 0.0, 0.0, 0.01808066759388039, 0.0, 0.0, 0.0, 0.0, 0.004172461752433936, 0.0013908205841446453, 0.0, 0.0, 0.0, 0.0, 0.012517385257301807, 0.0, 0.0013908205841446453, 0.0, 0.0013908205841446453, 0.0013908205841446453, 0.0, 0.005563282336578581, 0.0, 0.0, 0.005563282336578581, 0.0013908205841446453, 0.0, 0.019471488178025034, 0.0, 0.005563282336578581, 0.0013908205841446453, 0.0, 0.0, 0.0, 0.0027816411682892906, 0.0, 0.0013908205841446453, 0.0027816411682892906, 0.009735744089012517, 0.0, 0.0, 0.0013908205841446453, 0.004172461752433936, 0.0013908205841446453, 0.004172461752433936, 0.0, 0.0, 0.0, 0.013908205841446454, 0.0, 0.004172461752433936, 0.008344923504867872, 0.0027816411682892906, 0.0, 0.0, 0.009735744089012517, 0.0013908205841446453, 0.0, 0.0, 0.022253129346314324, 0.012517385257301807, 0.004172461752433936, 0.022253129346314324, 0.0, 0.004172461752433936, 0.0, 0.0, 0.0, 0.0013908205841446453, 0.0013908205841446453, 0.0, 0.0, 0.0027816411682892906, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005563282336578581, 0.005563282336578581, 0.019471488178025034, 0.009735744089012517, 0.0, 0.0, 0.0, 0.004172461752433936, 0.0, 0.0027816411682892906, 0.0, 0.0, 0.0027816411682892906, 0.0027816411682892906, 0.0, 0.009735744089012517, 0.0, 0.0, 0.0013908205841446453, 0.004172461752433936, 0.005563282336578581, 0.004172461752433936, 0.004172461752433936, 0.0, 0.0, 0.0, 0.004172461752433936, 0.012517385257301807, 0.0, 0.0, 0.0, 0.004172461752433936, 0.0, 0.0, 0.005563282336578581, 0.004172461752433936, 0.0, 0.0, 0.0013908205841446453, 0.0, 0.0, 0.006954102920723227, 0.0, 0.0, 0.0, 0.004172461752433936, 0.0, 0.0, 0.0, 0.004172461752433936, 0.0013908205841446453, 0.0013908205841446453, 0.004172461752433936, 0.0027816411682892906, 0.006954102920723227, 0.0, 0.0027816411682892906, 0.0013908205841446453, 0.0, 0.0, 0.0, 0.0013908205841446453, 0.0, 0.0013908205841446453, 0.0027816411682892906, 0.0013908205841446453, 0.006954102920723227, 0.0, 0.0027816411682892906, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0027816411682892906, 0.0, 0.0, 0.0, 0.012517385257301807, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0027816411682892906, 0.0, 0.0, 0.0027816411682892906, 0.005563282336578581, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005563282336578581, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.011126564673157162, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0027816411682892906, 0.004172461752433936, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004172461752433936, 0.0, 0.0013908205841446453, 0.005563282336578581, 0.0027816411682892906, 0.0, 0.0, 0.0, 0.0, 0.013908205841446454, 0.015299026425591099, 0.0, 0.0, 0.0013908205841446453, 0.0, 0.0, 0.008344923504867872, 0.0, 0.004172461752433936, 0.0, 0.0013908205841446453, 0.0, 0.0013908205841446453, 0.0, 0.0013908205841446453, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0027816411682892906, 0.009735744089012517, 0.0, 0.0, 0.0, 0.0, 0.004172461752433936, 0.0027816411682892906, 0.0, 0.0027816411682892906, 0.0, 0.0027816411682892906, 0.0, 0.0013908205841446453, 0.0, 0.0, 0.0013908205841446453, 0.0, 0.0013908205841446453, 0.0013908205841446453, 0.0, 0.0, 0.0, 0.005563282336578581, 0.0, 0.008344923504867872, 0.0, 0.0, 0.0013908205841446453, 0.0, 0.0, 0.0, 0.0, 0.0027816411682892906, 0.0, 0.0013908205841446453, 0.0013908205841446453, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0013908205841446453, 0.0, 0.0027816411682892906, 0.004172461752433936, 0.0, 0.0027816411682892906, 0.0, 0.008344923504867872, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0013908205841446453, 0.0013908205841446453, 0.005563282336578581, 0.0, 0.0027816411682892906, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004172461752433936, 0.0013908205841446453, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004172461752433936, 0.005563282336578581, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0027816411682892906, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0013908205841446453, 0.0, 0.0, 0.0, 0.0013908205841446453, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0013908205841446453, 0.0, 0.0013908205841446453, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0013908205841446453, 0.0, 0.0, 0.0, 0.0, 0.0013908205841446453, 0.0, 0.0027816411682892906, 0.0, 0.0013908205841446453, 0.0, 0.0, 0.0, 0.0, 0.009735744089012517, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005563282336578581, 0.0, 0.0, 0.009735744089012517, 0.0, 0.0027816411682892906, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0013908205841446453, 0.0027816411682892906, 0.0, 0.0, 0.0027816411682892906, 0.0, 0.0, 0.0, 0.0013908205841446453, 0.0027816411682892906, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0013908205841446453, 0.0, 0.0, 0.0, 0.0, 0.0027816411682892906, 0.0, 0.0, 0.0, 0.0, 0.0013908205841446453, 0.0, 0.0013908205841446453, 0.0, 0.0, 0.004172461752433936, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0013908205841446453, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0027816411682892906, 0.0, 0.0, 0.0013908205841446453, 0.0, 0.0, 0.0, 0.0027816411682892906, 0.0027816411682892906, 0.0, 0.0013908205841446453, 0.0, 0.0, 0.006954102920723227, 0.0, 0.0, 0.0, 0.0013908205841446453, 0.0, 0.0, 0.0027816411682892906, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005563282336578581, 0.0, 0.005563282336578581, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004172461752433936, 0.0, 0.0, 0.0, 0.0, 0.0027816411682892906, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0013908205841446453, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004172461752433936, 0.0, 0.0, 0.0, 0.0013908205841446453, 0.0, 0.0, 0.0, 0.0, 0.0013908205841446453, 0.0, 0.0, 0.0, 0.0, 0.0027816411682892906, 0.0013908205841446453, 0.0, 0.0013908205841446453, 0.0, 0.0, 0.0, 0.0013908205841446453, 0.0, 0.0013908205841446453, 0.0, 0.0, 0.0027816411682892906, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0027816411682892906, 0.0, 0.0, 0.0013908205841446453, 0.0027816411682892906, 0.0, 0.0013908205841446453, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0027816411682892906, 0.0013908205841446453, 0.0027816411682892906, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0027816411682892906, 0.0, 0.0, 0.0, 0.005563282336578581, 0.0, 0.004172461752433936, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004172461752433936, 0.0, 0.0, 0.0, 0.004172461752433936, 0.0027816411682892906, 0.0, 0.0, 0.004172461752433936, 0.0027816411682892906, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0027816411682892906, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0013908205841446453, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004172461752433936, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0027816411682892906, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0027816411682892906, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0013908205841446453, 0.0, 0.0, 0.0, 0.004172461752433936, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0027816411682892906, 0.0013908205841446453, 0.005563282336578581, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0027816411682892906, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0027816411682892906, 0.0, 0.0, 0.0, 0.0, 0.0013908205841446453, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004172461752433936, 0.0, 0.0, 0.0, 0.0, 0.0027816411682892906, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0013908205841446453, 0.0, 0.0, 0.0, 0.0027816411682892906, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0027816411682892906, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0027816411682892906, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004172461752433936, 0.0, 0.0027816411682892906, 0.0, 0.0, 0.0013908205841446453, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0013908205841446453, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], \"num_examples\": 719.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"Room\", \"threshold\": 2.5}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.0, 0.0, 0.0, 0.007653061224489796, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01020408163265306, 0.0, 0.0, 0.015306122448979591, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002551020408163265, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.012755102040816327, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015306122448979591, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002551020408163265, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007653061224489796, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00510204081632653, 0.0, 0.0, 0.0, 0.0, 0.017857142857142856, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007653061224489796, 0.0, 0.0, 0.0, 0.002551020408163265, 0.002551020408163265, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002551020408163265, 0.0, 0.0, 0.0, 0.0, 0.02295918367346939, 0.0, 0.0, 0.0, 0.002551020408163265, 0.002551020408163265, 0.0, 0.01020408163265306, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02040816326530612, 0.0, 0.007653061224489796, 0.002551020408163265, 0.0, 0.0, 0.0, 0.00510204081632653, 0.0, 0.0, 0.00510204081632653, 0.01020408163265306, 0.0, 0.0, 0.002551020408163265, 0.0, 0.0, 0.007653061224489796, 0.0, 0.0, 0.0, 0.007653061224489796, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002551020408163265, 0.002551020408163265, 0.0, 0.0, 0.04081632653061224, 0.00510204081632653, 0.007653061224489796, 0.017857142857142856, 0.0, 0.007653061224489796, 0.0, 0.0, 0.0, 0.002551020408163265, 0.002551020408163265, 0.0, 0.0, 0.00510204081632653, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01020408163265306, 0.015306122448979591, 0.0, 0.0, 0.0, 0.007653061224489796, 0.0, 0.00510204081632653, 0.0, 0.0, 0.00510204081632653, 0.00510204081632653, 0.0, 0.00510204081632653, 0.0, 0.0, 0.002551020408163265, 0.007653061224489796, 0.00510204081632653, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002551020408163265, 0.015306122448979591, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007653061224489796, 0.007653061224489796, 0.0, 0.0, 0.002551020408163265, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002551020408163265, 0.0, 0.0, 0.0, 0.007653061224489796, 0.002551020408163265, 0.002551020408163265, 0.007653061224489796, 0.002551020408163265, 0.012755102040816327, 0.0, 0.00510204081632653, 0.002551020408163265, 0.0, 0.0, 0.0, 0.002551020408163265, 0.0, 0.0, 0.00510204081632653, 0.002551020408163265, 0.007653061224489796, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00510204081632653, 0.0, 0.0, 0.0, 0.017857142857142856, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00510204081632653, 0.01020408163265306, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00510204081632653, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01020408163265306, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007653061224489796, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007653061224489796, 0.0, 0.002551020408163265, 0.007653061224489796, 0.00510204081632653, 0.0, 0.0, 0.0, 0.0, 0.002551020408163265, 0.017857142857142856, 0.0, 0.0, 0.002551020408163265, 0.0, 0.0, 0.002551020408163265, 0.0, 0.007653061224489796, 0.0, 0.0, 0.0, 0.002551020408163265, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00510204081632653, 0.01020408163265306, 0.0, 0.0, 0.0, 0.0, 0.007653061224489796, 0.00510204081632653, 0.0, 0.00510204081632653, 0.0, 0.00510204081632653, 0.0, 0.0, 0.0, 0.0, 0.002551020408163265, 0.0, 0.002551020408163265, 0.002551020408163265, 0.0, 0.0, 0.0, 0.01020408163265306, 0.0, 0.015306122448979591, 0.0, 0.0, 0.002551020408163265, 0.0, 0.0, 0.0, 0.0, 0.00510204081632653, 0.0, 0.0, 0.002551020408163265, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002551020408163265, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007653061224489796, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007653061224489796, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00510204081632653, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002551020408163265, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002551020408163265, 0.0, 0.00510204081632653, 0.0, 0.002551020408163265, 0.0, 0.0, 0.0, 0.0, 0.007653061224489796, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00510204081632653, 0.0, 0.0, 0.017857142857142856, 0.0, 0.00510204081632653, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002551020408163265, 0.0, 0.0, 0.00510204081632653, 0.0, 0.0, 0.0, 0.0, 0.00510204081632653, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002551020408163265, 0.0, 0.002551020408163265, 0.0, 0.0, 0.007653061224489796, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002551020408163265, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002551020408163265, 0.0, 0.0, 0.0, 0.00510204081632653, 0.0, 0.0, 0.002551020408163265, 0.0, 0.0, 0.012755102040816327, 0.0, 0.0, 0.0, 0.002551020408163265, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01020408163265306, 0.0, 0.01020408163265306, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007653061224489796, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002551020408163265, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007653061224489796, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002551020408163265, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002551020408163265, 0.0, 0.002551020408163265, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002551020408163265, 0.0, 0.0, 0.00510204081632653, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00510204081632653, 0.0, 0.0, 0.002551020408163265, 0.0, 0.0, 0.002551020408163265, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00510204081632653, 0.0, 0.00510204081632653, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00510204081632653, 0.0, 0.0, 0.0, 0.01020408163265306, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007653061224489796, 0.00510204081632653, 0.0, 0.0, 0.007653061224489796, 0.00510204081632653, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00510204081632653, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002551020408163265, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007653061224489796, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00510204081632653, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002551020408163265, 0.0, 0.0, 0.0, 0.007653061224489796, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01020408163265306, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007653061224489796, 0.0, 0.0, 0.0, 0.0, 0.00510204081632653, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00510204081632653, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007653061224489796, 0.0, 0.00510204081632653, 0.0, 0.0, 0.002551020408163265, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002551020408163265, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], \"num_examples\": 392.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"Price(USD)\", \"threshold\": 405000.0}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.0, 0.0, 0.0, 0.0030581039755351682, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0061162079510703364, 0.0, 0.0030581039755351682, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.009174311926605505, 0.0, 0.0, 0.009174311926605505, 0.0, 0.0030581039755351682, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0061162079510703364, 0.0, 0.012232415902140673, 0.0030581039755351682, 0.0, 0.0030581039755351682, 0.0, 0.0, 0.0, 0.0, 0.0, 0.009174311926605505, 0.0, 0.0, 0.0, 0.01834862385321101, 0.0, 0.03058103975535168, 0.0061162079510703364, 0.024464831804281346, 0.01529051987767584, 0.0, 0.0, 0.0, 0.0, 0.0, 0.021406727828746176, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0061162079510703364, 0.0, 0.0, 0.0, 0.0, 0.01834862385321101, 0.0, 0.0, 0.0, 0.0, 0.012232415902140673, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0030581039755351682, 0.0030581039755351682, 0.01834862385321101, 0.0, 0.0, 0.0, 0.0, 0.039755351681957186, 0.0, 0.0, 0.0, 0.0, 0.009174311926605505, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0030581039755351682, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.012232415902140673, 0.0030581039755351682, 0.0, 0.01834862385321101, 0.0, 0.0030581039755351682, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0030581039755351682, 0.0, 0.009174311926605505, 0.0, 0.0, 0.0, 0.009174311926605505, 0.0030581039755351682, 0.0, 0.0, 0.0, 0.0, 0.021406727828746176, 0.0, 0.009174311926605505, 0.01834862385321101, 0.0061162079510703364, 0.0, 0.0, 0.01834862385321101, 0.0, 0.0, 0.0, 0.0, 0.021406727828746176, 0.0, 0.027522935779816515, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.012232415902140673, 0.012232415902140673, 0.03058103975535168, 0.0030581039755351682, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01529051987767584, 0.0, 0.0, 0.0, 0.0, 0.0061162079510703364, 0.009174311926605505, 0.009174311926605505, 0.0, 0.0, 0.0, 0.0061162079510703364, 0.009174311926605505, 0.0, 0.0, 0.0, 0.009174311926605505, 0.0, 0.0, 0.0030581039755351682, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01529051987767584, 0.0, 0.0, 0.0, 0.0061162079510703364, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0030581039755351682, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0030581039755351682, 0.0, 0.0, 0.0061162079510703364, 0.0, 0.0061162079510703364, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0061162079510703364, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0061162079510703364, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0061162079510703364, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.012232415902140673, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0061162079510703364, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0030581039755351682, 0.0, 0.0, 0.0, 0.0, 0.0, 0.027522935779816515, 0.012232415902140673, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01529051987767584, 0.0, 0.0, 0.0, 0.0030581039755351682, 0.0, 0.0, 0.0, 0.0030581039755351682, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.009174311926605505, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0030581039755351682, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0030581039755351682, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0061162079510703364, 0.009174311926605505, 0.0, 0.0061162079510703364, 0.0, 0.009174311926605505, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0030581039755351682, 0.0030581039755351682, 0.012232415902140673, 0.0, 0.0061162079510703364, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0030581039755351682, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.009174311926605505, 0.012232415902140673, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0030581039755351682, 0.0, 0.0, 0.0, 0.0030581039755351682, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0030581039755351682, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0030581039755351682, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.012232415902140673, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0061162079510703364, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0030581039755351682, 0.0030581039755351682, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0030581039755351682, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0030581039755351682, 0.0, 0.0, 0.0, 0.0, 0.0061162079510703364, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0061162079510703364, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0061162079510703364, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0061162079510703364, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0061162079510703364, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0030581039755351682, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0061162079510703364, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0030581039755351682, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0061162079510703364, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0030581039755351682, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.009174311926605505, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.009174311926605505, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0061162079510703364, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0061162079510703364, 0.0030581039755351682, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0061162079510703364, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0061162079510703364, 0.0, 0.0, 0.0, 0.0, 0.0030581039755351682, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0030581039755351682, 0.0, 0.0, 0.0, 0.0061162079510703364, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0061162079510703364, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], \"num_examples\": 327.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"Price(USD)\", \"threshold\": 200833.34375}}]}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.004166666666666667, 0.022222222222222223, 0.0, 0.0, 0.015277777777777777, 0.0125, 0.002777777777777778, 0.0, 0.0, 0.002777777777777778, 0.001388888888888889, 0.0, 0.0, 0.0, 0.002777777777777778, 0.0, 0.005555555555555556, 0.0, 0.004166666666666667, 0.006944444444444444, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02361111111111111, 0.002777777777777778, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03194444444444444, 0.0, 0.0, 0.0, 0.002777777777777778, 0.0, 0.013888888888888888, 0.0, 0.0, 0.0, 0.0, 0.0, 0.009722222222222222, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015277777777777777, 0.005555555555555556, 0.019444444444444445, 0.008333333333333333, 0.0, 0.0, 0.0, 0.0, 0.002777777777777778, 0.006944444444444444, 0.0, 0.0125, 0.0, 0.0, 0.002777777777777778, 0.002777777777777778, 0.0, 0.0, 0.018055555555555554, 0.0, 0.0, 0.001388888888888889, 0.0, 0.008333333333333333, 0.006944444444444444, 0.002777777777777778, 0.011111111111111112, 0.0, 0.004166666666666667, 0.0, 0.011111111111111112, 0.0, 0.0, 0.0, 0.0, 0.002777777777777778, 0.004166666666666667, 0.002777777777777778, 0.0, 0.020833333333333332, 0.001388888888888889, 0.0, 0.0, 0.0, 0.0, 0.001388888888888889, 0.0, 0.0125, 0.013888888888888888, 0.0, 0.027777777777777776, 0.0, 0.001388888888888889, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002777777777777778, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002777777777777778, 0.02361111111111111, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001388888888888889, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004166666666666667, 0.0, 0.0, 0.0, 0.006944444444444444, 0.0, 0.002777777777777778, 0.0, 0.0, 0.006944444444444444, 0.006944444444444444, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001388888888888889, 0.001388888888888889, 0.0, 0.0, 0.011111111111111112, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005555555555555556, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001388888888888889, 0.0, 0.0, 0.0, 0.004166666666666667, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005555555555555556, 0.0, 0.0, 0.0, 0.0, 0.011111111111111112, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.011111111111111112, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005555555555555556, 0.0, 0.0, 0.0, 0.0, 0.002777777777777778, 0.0, 0.001388888888888889, 0.002777777777777778, 0.001388888888888889, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002777777777777778, 0.002777777777777778, 0.001388888888888889, 0.004166666666666667, 0.002777777777777778, 0.0, 0.0, 0.0, 0.005555555555555556, 0.0, 0.0, 0.005555555555555556, 0.0, 0.001388888888888889, 0.011111111111111112, 0.001388888888888889, 0.0, 0.001388888888888889, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005555555555555556, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004166666666666667, 0.0, 0.0, 0.001388888888888889, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002777777777777778, 0.0, 0.0, 0.006944444444444444, 0.0, 0.0, 0.0, 0.0, 0.004166666666666667, 0.001388888888888889, 0.011111111111111112, 0.0, 0.0, 0.0, 0.0, 0.002777777777777778, 0.0, 0.0, 0.0, 0.0, 0.001388888888888889, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002777777777777778, 0.0, 0.001388888888888889, 0.0, 0.002777777777777778, 0.0, 0.001388888888888889, 0.0, 0.0, 0.0, 0.0, 0.001388888888888889, 0.0, 0.020833333333333332, 0.0, 0.001388888888888889, 0.0, 0.0, 0.001388888888888889, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001388888888888889, 0.005555555555555556, 0.0, 0.001388888888888889, 0.001388888888888889, 0.0, 0.0, 0.0, 0.001388888888888889, 0.002777777777777778, 0.0, 0.0, 0.008333333333333333, 0.004166666666666667, 0.004166666666666667, 0.0, 0.0, 0.004166666666666667, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002777777777777778, 0.001388888888888889, 0.0, 0.0, 0.0, 0.0, 0.0, 0.006944444444444444, 0.005555555555555556, 0.004166666666666667, 0.011111111111111112, 0.0, 0.0, 0.002777777777777778, 0.016666666666666666, 0.0, 0.0, 0.001388888888888889, 0.0, 0.002777777777777778, 0.0, 0.002777777777777778, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005555555555555556, 0.0, 0.0, 0.002777777777777778, 0.002777777777777778, 0.0, 0.002777777777777778, 0.0, 0.001388888888888889, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004166666666666667, 0.0, 0.0, 0.0, 0.0, 0.001388888888888889, 0.001388888888888889, 0.0, 0.0, 0.0, 0.0, 0.002777777777777778, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005555555555555556, 0.001388888888888889, 0.0, 0.0, 0.0, 0.005555555555555556, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001388888888888889, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002777777777777778, 0.002777777777777778, 0.0, 0.0, 0.0, 0.0, 0.001388888888888889, 0.0, 0.0, 0.002777777777777778, 0.0, 0.0, 0.0, 0.002777777777777778, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001388888888888889, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.006944444444444444, 0.0, 0.0, 0.0, 0.001388888888888889, 0.0, 0.0, 0.0, 0.0, 0.001388888888888889, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001388888888888889, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001388888888888889, 0.0, 0.0, 0.0, 0.002777777777777778, 0.0, 0.0, 0.001388888888888889, 0.0, 0.0, 0.0, 0.0, 0.006944444444444444, 0.0, 0.0, 0.0, 0.0, 0.008333333333333333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002777777777777778, 0.0, 0.001388888888888889, 0.001388888888888889, 0.0, 0.004166666666666667, 0.005555555555555556, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001388888888888889, 0.001388888888888889, 0.0, 0.008333333333333333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005555555555555556, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001388888888888889, 0.001388888888888889, 0.0, 0.001388888888888889, 0.0, 0.0, 0.008333333333333333, 0.001388888888888889, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002777777777777778, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001388888888888889, 0.0, 0.004166666666666667, 0.0, 0.002777777777777778, 0.001388888888888889, 0.0, 0.002777777777777778, 0.001388888888888889, 0.0, 0.0, 0.001388888888888889, 0.0, 0.0, 0.0, 0.001388888888888889, 0.0, 0.0, 0.001388888888888889, 0.0, 0.001388888888888889, 0.006944444444444444, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002777777777777778, 0.002777777777777778, 0.001388888888888889, 0.001388888888888889, 0.0, 0.001388888888888889, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004166666666666667, 0.0, 0.006944444444444444, 0.002777777777777778, 0.002777777777777778, 0.0, 0.0, 0.001388888888888889, 0.001388888888888889, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001388888888888889, 0.0, 0.0, 0.0, 0.004166666666666667, 0.001388888888888889, 0.0, 0.0, 0.008333333333333333, 0.008333333333333333, 0.002777777777777778, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001388888888888889, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001388888888888889, 0.004166666666666667, 0.0, 0.002777777777777778, 0.0, 0.005555555555555556, 0.006944444444444444, 0.004166666666666667, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001388888888888889, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002777777777777778, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001388888888888889, 0.0, 0.001388888888888889, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004166666666666667, 0.0, 0.0, 0.001388888888888889, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002777777777777778, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001388888888888889, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001388888888888889, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002777777777777778, 0.001388888888888889, 0.0, 0.0, 0.0, 0.0, 0.002777777777777778, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001388888888888889, 0.0, 0.0, 0.0, 0.0, 0.004166666666666667, 0.0], \"num_examples\": 720.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"Price(USD)\", \"threshold\": 31750.0}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.008522727272727272, 0.0, 0.0, 0.0, 0.03125, 0.0, 0.005681818181818182, 0.0, 0.0, 0.005681818181818182, 0.002840909090909091, 0.0, 0.0, 0.0, 0.0, 0.0, 0.011363636363636364, 0.0, 0.008522727272727272, 0.014204545454545454, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.048295454545454544, 0.005681818181818182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06534090909090909, 0.0, 0.0, 0.0, 0.005681818181818182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.019886363636363636, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.011363636363636364, 0.03977272727272727, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02556818181818182, 0.0, 0.0, 0.005681818181818182, 0.005681818181818182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008522727272727272, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008522727272727272, 0.005681818181818182, 0.0, 0.04261363636363636, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002840909090909091, 0.0, 0.02556818181818182, 0.028409090909090908, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005681818181818182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005681818181818182, 0.048295454545454544, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002840909090909091, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.014204545454545454, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002840909090909091, 0.0, 0.0, 0.022727272727272728, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002840909090909091, 0.0, 0.0, 0.0, 0.008522727272727272, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.011363636363636364, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005681818181818182, 0.0, 0.002840909090909091, 0.0, 0.002840909090909091, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005681818181818182, 0.005681818181818182, 0.002840909090909091, 0.008522727272727272, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022727272727272728, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.011363636363636364, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008522727272727272, 0.0, 0.0, 0.002840909090909091, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.014204545454545454, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002840909090909091, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002840909090909091, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002840909090909091, 0.0, 0.005681818181818182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002840909090909091, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002840909090909091, 0.011363636363636364, 0.0, 0.0, 0.002840909090909091, 0.0, 0.0, 0.0, 0.002840909090909091, 0.005681818181818182, 0.0, 0.0, 0.017045454545454544, 0.008522727272727272, 0.0, 0.0, 0.0, 0.008522727272727272, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002840909090909091, 0.0, 0.0, 0.0, 0.0, 0.0, 0.014204545454545454, 0.0, 0.008522727272727272, 0.022727272727272728, 0.0, 0.0, 0.005681818181818182, 0.0, 0.0, 0.0, 0.002840909090909091, 0.0, 0.0, 0.0, 0.005681818181818182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005681818181818182, 0.0, 0.002840909090909091, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002840909090909091, 0.0, 0.0, 0.0, 0.0, 0.005681818181818182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002840909090909091, 0.0, 0.0, 0.0, 0.011363636363636364, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002840909090909091, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005681818181818182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002840909090909091, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.014204545454545454, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005681818181818182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002840909090909091, 0.002840909090909091, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002840909090909091, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002840909090909091, 0.002840909090909091, 0.0, 0.0, 0.0, 0.0, 0.017045454545454544, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008522727272727272, 0.0, 0.005681818181818182, 0.002840909090909091, 0.0, 0.005681818181818182, 0.002840909090909091, 0.0, 0.0, 0.002840909090909091, 0.0, 0.0, 0.0, 0.002840909090909091, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005681818181818182, 0.0, 0.0, 0.002840909090909091, 0.0, 0.002840909090909091, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008522727272727272, 0.0, 0.014204545454545454, 0.0, 0.0, 0.0, 0.0, 0.002840909090909091, 0.002840909090909091, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002840909090909091, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002840909090909091, 0.008522727272727272, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002840909090909091, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008522727272727272, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005681818181818182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002840909090909091, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], \"num_examples\": 352.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"Price(USD)\", \"threshold\": 49333.3359375}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.0, 0.043478260869565216, 0.0, 0.0, 0.0, 0.024456521739130436, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005434782608695652, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02717391304347826, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.029891304347826088, 0.0, 0.0, 0.016304347826086956, 0.0, 0.0, 0.0, 0.0, 0.005434782608695652, 0.01358695652173913, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.035326086956521736, 0.0, 0.0, 0.002717391304347826, 0.0, 0.016304347826086956, 0.01358695652173913, 0.005434782608695652, 0.021739130434782608, 0.0, 0.0, 0.0, 0.021739130434782608, 0.0, 0.0, 0.0, 0.0, 0.005434782608695652, 0.0, 0.0, 0.0, 0.0, 0.002717391304347826, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05434782608695652, 0.0, 0.002717391304347826, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008152173913043478, 0.0, 0.0, 0.0, 0.01358695652173913, 0.0, 0.005434782608695652, 0.0, 0.0, 0.01358695652173913, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002717391304347826, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.010869565217391304, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.021739130434782608, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.021739130434782608, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.010869565217391304, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005434782608695652, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005434782608695652, 0.0, 0.0, 0.0, 0.010869565217391304, 0.0, 0.0, 0.010869565217391304, 0.0, 0.002717391304347826, 0.0, 0.002717391304347826, 0.0, 0.002717391304347826, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005434782608695652, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008152173913043478, 0.0, 0.021739130434782608, 0.0, 0.0, 0.0, 0.0, 0.005434782608695652, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005434782608695652, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002717391304347826, 0.0, 0.0, 0.0, 0.0, 0.002717391304347826, 0.0, 0.04076086956521739, 0.0, 0.002717391304347826, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002717391304347826, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008152173913043478, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005434782608695652, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.010869565217391304, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03260869565217391, 0.0, 0.0, 0.0, 0.0, 0.005434782608695652, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.010869565217391304, 0.0, 0.0, 0.005434782608695652, 0.005434782608695652, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008152173913043478, 0.0, 0.0, 0.0, 0.0, 0.002717391304347826, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.010869565217391304, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005434782608695652, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005434782608695652, 0.0, 0.0, 0.0, 0.005434782608695652, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002717391304347826, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002717391304347826, 0.0, 0.0, 0.0, 0.0, 0.002717391304347826, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002717391304347826, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002717391304347826, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002717391304347826, 0.0, 0.0, 0.0, 0.0, 0.01358695652173913, 0.0, 0.0, 0.0, 0.0, 0.016304347826086956, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005434782608695652, 0.0, 0.0, 0.0, 0.0, 0.008152173913043478, 0.010869565217391304, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002717391304347826, 0.0, 0.0, 0.016304347826086956, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.010869565217391304, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002717391304347826, 0.0, 0.0, 0.0, 0.002717391304347826, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005434782608695652, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002717391304347826, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002717391304347826, 0.0, 0.002717391304347826, 0.01358695652173913, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005434782608695652, 0.002717391304347826, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005434782608695652, 0.005434782608695652, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008152173913043478, 0.002717391304347826, 0.0, 0.0, 0.016304347826086956, 0.016304347826086956, 0.005434782608695652, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002717391304347826, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005434782608695652, 0.0, 0.010869565217391304, 0.01358695652173913, 0.008152173913043478, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002717391304347826, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005434782608695652, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002717391304347826, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002717391304347826, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002717391304347826, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005434782608695652, 0.002717391304347826, 0.0, 0.0, 0.0, 0.0, 0.005434782608695652, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002717391304347826, 0.0, 0.0, 0.0, 0.0, 0.008152173913043478, 0.0], \"num_examples\": 368.0}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"Address\", \"mask\": [\"Parand\", \"Andisheh\", \"Golestan\", \"Azarbaijan\", \"Hashemi\"]}}]}]}]}, \"#tree_plot_bf8bbad3cc1148239fd5c8fc7c1f904f\")\n",
              "</script>\n"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " sử dụng để hiển thị hình ảnh trực quan của một cây quyết định từ mô hình RandomForestModel"
      ],
      "metadata": {
        "id": "SM5zozmFTK9U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.summary()"
      ],
      "metadata": {
        "id": "13UCqID6TLYJ",
        "outputId": "07192971-ecae-4580-9e38-33049e5f2391",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"random_forest_model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            "=================================================================\n",
            "Total params: 1 (1.00 Byte)\n",
            "Trainable params: 0 (0.00 Byte)\n",
            "Non-trainable params: 1 (1.00 Byte)\n",
            "_________________________________________________________________\n",
            "Type: \"RANDOM_FOREST\"\n",
            "Task: CLASSIFICATION\n",
            "Label: \"__LABEL\"\n",
            "\n",
            "Input Features (7):\n",
            "\tAddress\n",
            "\tArea\n",
            "\tElevator\n",
            "\tParking\n",
            "\tPrice(USD)\n",
            "\tRoom\n",
            "\tWarehouse\n",
            "\n",
            "No weights\n",
            "\n",
            "Variable Importance: INV_MEAN_MIN_DEPTH:\n",
            "    1. \"Price(USD)\"  0.762570 ################\n",
            "    2.    \"Address\"  0.225006 ##\n",
            "    3.       \"Area\"  0.173039 #\n",
            "    4.       \"Room\"  0.130553 \n",
            "    5.   \"Elevator\"  0.106217 \n",
            "    6.  \"Warehouse\"  0.104966 \n",
            "    7.    \"Parking\"  0.104893 \n",
            "\n",
            "Variable Importance: NUM_AS_ROOT:\n",
            "    1. \"Price(USD)\" 11.000000 ################\n",
            "    2.    \"Address\"  3.000000 \n",
            "\n",
            "Variable Importance: NUM_NODES:\n",
            "    1. \"Price(USD)\" 2594.000000 ################\n",
            "    2.       \"Area\" 1214.000000 #######\n",
            "    3.    \"Address\" 866.000000 #####\n",
            "    4.       \"Room\" 50.000000 \n",
            "    5.   \"Elevator\" 39.000000 \n",
            "    6.    \"Parking\" 27.000000 \n",
            "    7.  \"Warehouse\" 18.000000 \n",
            "\n",
            "Variable Importance: SUM_SCORE:\n",
            "    1. \"Price(USD)\" 125856.609573 ################\n",
            "    2.       \"Area\" 23695.929292 ##\n",
            "    3.    \"Address\" 22240.470230 ##\n",
            "    4.       \"Room\" 4228.887811 \n",
            "    5.   \"Elevator\" 605.025973 \n",
            "    6.  \"Warehouse\" 322.293774 \n",
            "    7.    \"Parking\" 307.215368 \n",
            "\n",
            "\n",
            "\n",
            "Winner takes all: true\n",
            "Out-of-bag evaluation: accuracy:0.347433 logloss:17.6478\n",
            "Number of trees: 14\n",
            "Total number of nodes: 9630\n",
            "\n",
            "Number of nodes by tree:\n",
            "Count: 14 Average: 687.857 StdDev: 16.0662\n",
            "Min: 665 Max: 715 Ignored: 0\n",
            "----------------------------------------------\n",
            "[ 665, 667) 1   7.14%   7.14% ###\n",
            "[ 667, 670) 1   7.14%  14.29% ###\n",
            "[ 670, 672) 1   7.14%  21.43% ###\n",
            "[ 672, 675) 1   7.14%  28.57% ###\n",
            "[ 675, 677) 0   0.00%  28.57%\n",
            "[ 677, 680) 3  21.43%  50.00% ##########\n",
            "[ 680, 682) 0   0.00%  50.00%\n",
            "[ 682, 685) 0   0.00%  50.00%\n",
            "[ 685, 687) 0   0.00%  50.00%\n",
            "[ 687, 690) 1   7.14%  57.14% ###\n",
            "[ 690, 693) 0   0.00%  57.14%\n",
            "[ 693, 695) 1   7.14%  64.29% ###\n",
            "[ 695, 698) 0   0.00%  64.29%\n",
            "[ 698, 700) 2  14.29%  78.57% #######\n",
            "[ 700, 703) 0   0.00%  78.57%\n",
            "[ 703, 705) 0   0.00%  78.57%\n",
            "[ 705, 708) 0   0.00%  78.57%\n",
            "[ 708, 710) 1   7.14%  85.71% ###\n",
            "[ 710, 713) 1   7.14%  92.86% ###\n",
            "[ 713, 715] 1   7.14% 100.00% ###\n",
            "\n",
            "Depth by leafs:\n",
            "Count: 4822 Average: 8.57175 StdDev: 0.64252\n",
            "Min: 6 Max: 10 Ignored: 0\n",
            "----------------------------------------------\n",
            "[  6,  7)    9   0.19%   0.19%\n",
            "[  7,  8)  112   2.32%   2.51%\n",
            "[  8,  9) 2080  43.14%  45.64% #########\n",
            "[  9, 10) 2355  48.84%  94.48% ##########\n",
            "[ 10, 10]  266   5.52% 100.00% #\n",
            "\n",
            "Number of training obs by leaf:\n",
            "Count: 4822 Average: 7.08129 StdDev: 2.56351\n",
            "Min: 5 Max: 34 Ignored: 0\n",
            "----------------------------------------------\n",
            "[  5,  6) 1359  28.18%  28.18% #######\n",
            "[  6,  8) 1907  39.55%  67.73% ##########\n",
            "[  8,  9)  662  13.73%  81.46% ###\n",
            "[  9, 11)  623  12.92%  94.38% ###\n",
            "[ 11, 12)   65   1.35%  95.73%\n",
            "[ 12, 14)   71   1.47%  97.20%\n",
            "[ 14, 15)   25   0.52%  97.72%\n",
            "[ 15, 17)   41   0.85%  98.57%\n",
            "[ 17, 18)   11   0.23%  98.80%\n",
            "[ 18, 20)   26   0.54%  99.34%\n",
            "[ 20, 21)    4   0.08%  99.42%\n",
            "[ 21, 23)   10   0.21%  99.63%\n",
            "[ 23, 24)    5   0.10%  99.73%\n",
            "[ 24, 26)    2   0.04%  99.77%\n",
            "[ 26, 27)    3   0.06%  99.83%\n",
            "[ 27, 29)    3   0.06%  99.90%\n",
            "[ 29, 30)    2   0.04%  99.94%\n",
            "[ 30, 32)    2   0.04%  99.98%\n",
            "[ 32, 33)    0   0.00%  99.98%\n",
            "[ 33, 34]    1   0.02% 100.00%\n",
            "\n",
            "Attribute in nodes:\n",
            "\t2594 : Price(USD) [NUMERICAL]\n",
            "\t1214 : Area [CATEGORICAL]\n",
            "\t866 : Address [CATEGORICAL]\n",
            "\t50 : Room [NUMERICAL]\n",
            "\t39 : Elevator [NUMERICAL]\n",
            "\t27 : Parking [NUMERICAL]\n",
            "\t18 : Warehouse [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 0:\n",
            "\t11 : Price(USD) [NUMERICAL]\n",
            "\t3 : Address [CATEGORICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 1:\n",
            "\t30 : Price(USD) [NUMERICAL]\n",
            "\t5 : Room [NUMERICAL]\n",
            "\t5 : Address [CATEGORICAL]\n",
            "\t2 : Area [CATEGORICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 2:\n",
            "\t55 : Price(USD) [NUMERICAL]\n",
            "\t20 : Address [CATEGORICAL]\n",
            "\t14 : Area [CATEGORICAL]\n",
            "\t9 : Room [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 3:\n",
            "\t119 : Price(USD) [NUMERICAL]\n",
            "\t48 : Address [CATEGORICAL]\n",
            "\t32 : Area [CATEGORICAL]\n",
            "\t10 : Room [NUMERICAL]\n",
            "\t1 : Elevator [NUMERICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 5:\n",
            "\t576 : Price(USD) [NUMERICAL]\n",
            "\t143 : Area [CATEGORICAL]\n",
            "\t136 : Address [CATEGORICAL]\n",
            "\t16 : Room [NUMERICAL]\n",
            "\t5 : Elevator [NUMERICAL]\n",
            "\t4 : Warehouse [NUMERICAL]\n",
            "\t2 : Parking [NUMERICAL]\n",
            "\n",
            "Condition type in nodes:\n",
            "\t2728 : HigherCondition\n",
            "\t1257 : ContainsBitmapCondition\n",
            "\t823 : ContainsCondition\n",
            "Condition type in nodes with depth <= 0:\n",
            "\t11 : HigherCondition\n",
            "\t3 : ContainsBitmapCondition\n",
            "Condition type in nodes with depth <= 1:\n",
            "\t35 : HigherCondition\n",
            "\t7 : ContainsBitmapCondition\n",
            "Condition type in nodes with depth <= 2:\n",
            "\t64 : HigherCondition\n",
            "\t33 : ContainsBitmapCondition\n",
            "\t1 : ContainsCondition\n",
            "Condition type in nodes with depth <= 3:\n",
            "\t130 : HigherCondition\n",
            "\t78 : ContainsBitmapCondition\n",
            "\t2 : ContainsCondition\n",
            "Condition type in nodes with depth <= 5:\n",
            "\t603 : HigherCondition\n",
            "\t271 : ContainsBitmapCondition\n",
            "\t8 : ContainsCondition\n",
            "Node format: NOT_SET\n",
            "\n",
            "Training OOB:\n",
            "\ttrees: 1, Out-of-bag evaluation: accuracy:0.246652 logloss:27.1534\n",
            "\ttrees: 3, Out-of-bag evaluation: accuracy:0.286424 logloss:24.1032\n",
            "\ttrees: 6, Out-of-bag evaluation: accuracy:0.308234 logloss:21.5953\n",
            "\ttrees: 8, Out-of-bag evaluation: accuracy:0.312868 logloss:20.4532\n",
            "\ttrees: 11, Out-of-bag evaluation: accuracy:0.341303 logloss:18.4161\n",
            "\ttrees: 13, Out-of-bag evaluation: accuracy:0.347433 logloss:17.6478\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The input features\n",
        "model_1.make_inspector().features()"
      ],
      "metadata": {
        "id": "qjPlr6x7Tj2q",
        "outputId": "201806af-0ea4-4d03-b3be-f95fcf017c10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"Address\" (4; #0),\n",
              " \"Area\" (4; #1),\n",
              " \"Elevator\" (1; #2),\n",
              " \"Parking\" (1; #3),\n",
              " \"Price(USD)\" (1; #4),\n",
              " \"Room\" (1; #5),\n",
              " \"Warehouse\" (1; #6)]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The feature importances\n",
        "model_1.make_inspector().variable_importances()"
      ],
      "metadata": {
        "id": "NhWhrIcNTr7G",
        "outputId": "4ae3dccc-2017-4e13-b4d0-44fcdfe479cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'INV_MEAN_MIN_DEPTH': [(\"Price(USD)\" (1; #4), 0.7625701428347144),\n",
              "  (\"Address\" (4; #0), 0.2250058043577017),\n",
              "  (\"Area\" (4; #1), 0.17303936163593578),\n",
              "  (\"Room\" (1; #5), 0.13055296177750236),\n",
              "  (\"Elevator\" (1; #2), 0.10621691025689535),\n",
              "  (\"Warehouse\" (1; #6), 0.10496583519202395),\n",
              "  (\"Parking\" (1; #3), 0.10489260981816843)],\n",
              " 'NUM_AS_ROOT': [(\"Price(USD)\" (1; #4), 11.0), (\"Address\" (4; #0), 3.0)],\n",
              " 'SUM_SCORE': [(\"Price(USD)\" (1; #4), 125856.60957339406),\n",
              "  (\"Area\" (4; #1), 23695.929291918874),\n",
              "  (\"Address\" (4; #0), 22240.470229756087),\n",
              "  (\"Room\" (1; #5), 4228.887811124325),\n",
              "  (\"Elevator\" (1; #2), 605.0259734690189),\n",
              "  (\"Warehouse\" (1; #6), 322.29377394914627),\n",
              "  (\"Parking\" (1; #3), 307.2153676301241)],\n",
              " 'NUM_NODES': [(\"Price(USD)\" (1; #4), 2594.0),\n",
              "  (\"Area\" (4; #1), 1214.0),\n",
              "  (\"Address\" (4; #0), 866.0),\n",
              "  (\"Room\" (1; #5), 50.0),\n",
              "  (\"Elevator\" (1; #2), 39.0),\n",
              "  (\"Parking\" (1; #3), 27.0),\n",
              "  (\"Warehouse\" (1; #6), 18.0)]}"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "sử dụng để truy xuất độ quan trọng của các biến (feature importances) trong mô hình RandomForestModel"
      ],
      "metadata": {
        "id": "0yc-2a_DXUpD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.make_inspector().evaluation()"
      ],
      "metadata": {
        "id": "QkvdPPq_T-hF",
        "outputId": "149ee22b-1bb9-42ea-9f21-921f420acb26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Evaluation(num_examples=2435, accuracy=0.34743326488706366, loss=17.647825250464052, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "model_1.make_inspector().evaluation() được sử dụng để đánh giá mô hình RandomForestModel đã được huấn luyện trên tập dữ liệu"
      ],
      "metadata": {
        "id": "MKvxM5xcXElb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sơ đồ training"
      ],
      "metadata": {
        "id": "aMWOcJQGUNtb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.make_inspector().training_logs()"
      ],
      "metadata": {
        "id": "MKC07gOsUPnD",
        "outputId": "8ec80624-0127-4114-9e58-7c1af38cf946",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[TrainLog(num_trees=1, evaluation=Evaluation(num_examples=896, accuracy=0.24665178571428573, loss=27.153420554740087, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
              " TrainLog(num_trees=3, evaluation=Evaluation(num_examples=1812, accuracy=0.28642384105960267, loss=24.10316204274727, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
              " TrainLog(num_trees=6, evaluation=Evaluation(num_examples=2271, accuracy=0.30823425803610743, loss=21.595334421546383, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
              " TrainLog(num_trees=8, evaluation=Evaluation(num_examples=2378, accuracy=0.3128679562657696, loss=20.45318857545332, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
              " TrainLog(num_trees=11, evaluation=Evaluation(num_examples=2426, accuracy=0.34130255564715584, loss=18.41612076412914, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n",
              " TrainLog(num_trees=13, evaluation=Evaluation(num_examples=2435, accuracy=0.34743326488706366, loss=17.647825250464052, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None))]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "logs = model_1.make_inspector().training_logs()\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot([log.num_trees for log in logs], [log.evaluation.accuracy for log in logs])\n",
        "plt.xlabel(\"Number of trees\")\n",
        "plt.ylabel(\"Accuracy (out-of-bag)\")\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot([log.num_trees for log in logs], [log.evaluation.loss for log in logs])\n",
        "plt.xlabel(\"Number of trees\")\n",
        "plt.ylabel(\"Logloss (out-of-bag)\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bcmGZj6xUaUj",
        "outputId": "ab19849b-8514-45b9-be72-f2469d5c81a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vẽ biểu đồ để trực quan hóa quá trình huấn luyện, bao gồm độ chính xác và độ mất mát theo số lượng cây trong rừng."
      ],
      "metadata": {
        "id": "15D_-60aW5-s"
      }
    }
  ]
}